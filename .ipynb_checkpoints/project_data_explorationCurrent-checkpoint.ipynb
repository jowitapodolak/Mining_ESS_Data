{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UNsiQPlqloes"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "nrEwOVYT3az3",
    "outputId": "36084a45-7d66-425d-81d4-14b63bd7cd63"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; \n",
    "import math\n",
    "# helper functions for normalisatio\n",
    "from utils import * \n",
    "#TO BE CHANGED ON YOUR COMPUTERS\n",
    "data_info = pd.read_csv('/Users/jowi/uni/DataMining/DataMining-FinalProject/european-social-survey/variables.csv') #metadata\n",
    "#TO BE CHANGED ON YOUR COMPUTERS\n",
    "data = pd.read_csv('/Users/jowi/uni/DataMining/DataMining-FinalProject/european-social-survey/ESS8e02.1_F1.csv') #data\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "#print(data['Question']) <- see all the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S7kDzABOltJr"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyK4Ptpzlgvn"
   },
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UpXF9MwVna6a"
   },
   "source": [
    "https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/\n",
    "for checking best k out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "Choose columns (features) to be fed to our models:\n",
    "  1. No country specific columns \n",
    "  2. Change cathegorical string values to numeric values - First find all strings columns - this we hava not done but could) \n",
    "  3. Produce a list of columns based on above (later we are going to drop idno, lrscale)\n",
    "  4. Format column in data info has value \"numeric\" as a substring (numeric- 1.0,2.0, and 4.0 included)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSZv92p8o8zC"
   },
   "outputs": [],
   "source": [
    "#  4 \n",
    "data_sliced = numeric_features(data, data_info)\n",
    "columns_no_cntry =  data_sliced.drop(columns='cntry').columns # used later\n",
    "# data_sliced is now a data limited to only the column with numerical values and country-agnostic (country-independent) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0AhlIoXl52x"
   },
   "source": [
    "### NaN - Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace NaN with mean for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 823
    },
    "colab_type": "code",
    "id": "gDHtgiF-3GXH",
    "outputId": "0aa39d26-ef60-4636-d3af-5f422b29106b"
   },
   "outputs": [],
   "source": [
    "#data_sliced = replace_nan(data_sliced, columns_no_cntry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_target_column' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8e00af6d0cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_sliced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_target_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sliced\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# lrscale3 added to data_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'add_target_column' is not defined"
     ]
    }
   ],
   "source": [
    "data_sliced = add_target_column(data_sliced) # lrscale3 added to data_sliced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZATION  \n",
    "We do normalization after adding the column lrscale3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALIZATION  - to be used by K-means - decision trees don't need normalisation (so USE data_slicedNormalised instead of data_sliced)\n",
    "data_sliced_normalised = normalize_data(data_sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzqvBjth3GXt"
   },
   "outputs": [],
   "source": [
    "countries = data[['name','cntry']].groupby('cntry')\n",
    "#After this operation I get a dataframe wiht idno as a column name anc=d cntry as INDEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJybKAOX317J"
   },
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TT6OZ0ds4B6-"
   },
   "outputs": [],
   "source": [
    "# Use clustering to remove outliers\n",
    "# maybe we should have clusters based on the political view and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4uvkcNOwsQ2T"
   },
   "source": [
    "# Explorary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CVe8terNvZAu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qxnF1nbN3Fh_"
   },
   "source": [
    "### Central Tendencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0S09yfw3KGq"
   },
   "outputs": [],
   "source": [
    "# mean, median, mode, variance/standard deviation, quantils-analysis of political view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "HGf95s1E5mHu",
    "outputId": "978989b4-9445-43bc-e132-35ce7d5eca48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    44387.000000\n",
       "mean         5.164637\n",
       "std          2.091008\n",
       "min          0.000000\n",
       "25%          4.000000\n",
       "50%          5.000000\n",
       "75%          6.000000\n",
       "max         10.000000\n",
       "Name: lrscale, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['lrscale'].describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "nAuBbrCF6ayU",
    "outputId": "d6e2de82-4cbf-4b39-cda3-017dee7e4db2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2271ea58>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data_sliced['lrscale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "naSFTomRRSvg",
    "outputId": "4057d40f-2eb6-47e3-9e71-0158f5df3592"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a253868d0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#countries_politicalOrientation = data_sliced[['cntry','lrscale']].groupby('cntry')\n",
    "sns.boxenplot(y=\"lrscale\",x=\"cntry\",data=data_sliced[['cntry','lrscale']], palette='rainbow',width=1.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOyvtf-WacU2"
   },
   "source": [
    "Possible countries to look at:\n",
    "- PT\n",
    "- ES\n",
    "- IL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBNhcTShinU0"
   },
   "source": [
    "Calculate standard deviation for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "colab_type": "code",
    "id": "26KR1TOaaydD",
    "outputId": "a37ad481-a014-4d3e-fc17-e1aaf73dffdd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lrscale</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cntry</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>2.798551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>2.317978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>2.306259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HU</th>\n",
       "      <td>2.272381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>2.223621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL</th>\n",
       "      <td>2.223416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>2.184726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS</th>\n",
       "      <td>2.163792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>2.088510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CZ</th>\n",
       "      <td>2.081414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH</th>\n",
       "      <td>2.068719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FI</th>\n",
       "      <td>2.049845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>2.039466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>2.031836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>1.947538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BE</th>\n",
       "      <td>1.936479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL</th>\n",
       "      <td>1.904661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IE</th>\n",
       "      <td>1.834421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>1.823782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EE</th>\n",
       "      <td>1.816985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>1.803233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT</th>\n",
       "      <td>1.730843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RU</th>\n",
       "      <td>1.588752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lrscale\n",
       "cntry          \n",
       "IL     2.798551\n",
       "FR     2.317978\n",
       "PT     2.306259\n",
       "HU     2.272381\n",
       "SE     2.223621\n",
       "PL     2.223416\n",
       "NO     2.184726\n",
       "IS     2.163792\n",
       "SI     2.088510\n",
       "CZ     2.081414\n",
       "CH     2.068719\n",
       "FI     2.049845\n",
       "ES     2.039466\n",
       "IT     2.031836\n",
       "AT     1.947538\n",
       "BE     1.936479\n",
       "NL     1.904661\n",
       "IE     1.834421\n",
       "DE     1.823782\n",
       "EE     1.816985\n",
       "GB     1.803233\n",
       "LT     1.730843\n",
       "RU     1.588752"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standarddev_country = data_sliced[['cntry','lrscale']].groupby('cntry').std()\n",
    "standarddev_country.sort_values('lrscale', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xoWVdNXtmEA4"
   },
   "source": [
    "### Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "664R-flHtj6X",
    "outputId": "7a95a61d-2a92-4154-822a-f23a652f1913"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dweight</th>\n",
       "      <th>pspwght</th>\n",
       "      <th>pweight</th>\n",
       "      <th>nwspol</th>\n",
       "      <th>netustm</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>trstprl</th>\n",
       "      <th>trstlgl</th>\n",
       "      <th>...</th>\n",
       "      <th>inwdds</th>\n",
       "      <th>inwmms</th>\n",
       "      <th>inwshh</th>\n",
       "      <th>inwsmm</th>\n",
       "      <th>inwdde</th>\n",
       "      <th>inwmme</th>\n",
       "      <th>inwehh</th>\n",
       "      <th>inwemm</th>\n",
       "      <th>inwtm</th>\n",
       "      <th>lrscale3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.00000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "      <td>44387.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.174817</td>\n",
       "      <td>189.474130</td>\n",
       "      <td>2299.112859</td>\n",
       "      <td>5.268402</td>\n",
       "      <td>5.80346</td>\n",
       "      <td>5.208980</td>\n",
       "      <td>4.581889</td>\n",
       "      <td>5.411768</td>\n",
       "      <td>...</td>\n",
       "      <td>15.831476</td>\n",
       "      <td>8.133128</td>\n",
       "      <td>14.267075</td>\n",
       "      <td>25.507198</td>\n",
       "      <td>15.834873</td>\n",
       "      <td>8.134595</td>\n",
       "      <td>15.333992</td>\n",
       "      <td>28.851623</td>\n",
       "      <td>65.045491</td>\n",
       "      <td>1.139996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.390219</td>\n",
       "      <td>0.548561</td>\n",
       "      <td>1.301596</td>\n",
       "      <td>962.889106</td>\n",
       "      <td>3062.980607</td>\n",
       "      <td>2.362596</td>\n",
       "      <td>2.17488</td>\n",
       "      <td>2.249206</td>\n",
       "      <td>2.531860</td>\n",
       "      <td>2.588719</td>\n",
       "      <td>...</td>\n",
       "      <td>8.639183</td>\n",
       "      <td>3.828512</td>\n",
       "      <td>3.150605</td>\n",
       "      <td>18.402467</td>\n",
       "      <td>8.642332</td>\n",
       "      <td>3.828660</td>\n",
       "      <td>3.146533</td>\n",
       "      <td>17.527958</td>\n",
       "      <td>26.372867</td>\n",
       "      <td>0.837439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.036070</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>0.030226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.915591</td>\n",
       "      <td>0.694870</td>\n",
       "      <td>0.239750</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920021</td>\n",
       "      <td>0.520820</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.044025</td>\n",
       "      <td>1.169933</td>\n",
       "      <td>2.013008</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>6666.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.206992</td>\n",
       "      <td>4.002002</td>\n",
       "      <td>4.985758</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1083.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dweight       pspwght       pweight        nwspol       netustm  \\\n",
       "count  44387.000000  44387.000000  44387.000000  44387.000000  44387.000000   \n",
       "mean       1.000000      1.000000      1.174817    189.474130   2299.112859   \n",
       "std        0.390219      0.548561      1.301596    962.889106   3062.980607   \n",
       "min        0.036070      0.018145      0.030226      0.000000      0.000000   \n",
       "25%        0.915591      0.694870      0.239750     30.000000    120.000000   \n",
       "50%        1.000000      0.920021      0.520820     60.000000    240.000000   \n",
       "75%        1.044025      1.169933      2.013008     90.000000   6666.000000   \n",
       "max        6.206992      4.002002      4.985758   9999.000000   9999.000000   \n",
       "\n",
       "            ppltrst      pplfair        pplhlp       trstprl       trstlgl  \\\n",
       "count  44387.000000  44387.00000  44387.000000  44387.000000  44387.000000   \n",
       "mean       5.268402      5.80346      5.208980      4.581889      5.411768   \n",
       "std        2.362596      2.17488      2.249206      2.531860      2.588719   \n",
       "min        0.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%        4.000000      5.00000      4.000000      3.000000      4.000000   \n",
       "50%        5.000000      6.00000      5.000000      5.000000      6.000000   \n",
       "75%        7.000000      7.00000      7.000000      6.000000      7.000000   \n",
       "max       10.000000     10.00000     10.000000     10.000000     10.000000   \n",
       "\n",
       "       ...        inwdds        inwmms        inwshh        inwsmm  \\\n",
       "count  ...  44387.000000  44387.000000  44387.000000  44387.000000   \n",
       "mean   ...     15.831476      8.133128     14.267075     25.507198   \n",
       "std    ...      8.639183      3.828512      3.150605     18.402467   \n",
       "min    ...      1.000000      1.000000      0.000000      0.000000   \n",
       "25%    ...      8.000000      5.000000     12.000000      9.000000   \n",
       "50%    ...     16.000000     10.000000     14.000000     24.000000   \n",
       "75%    ...     23.000000     11.000000     17.000000     41.000000   \n",
       "max    ...     31.000000     12.000000     23.000000     59.000000   \n",
       "\n",
       "             inwdde        inwmme        inwehh        inwemm         inwtm  \\\n",
       "count  44387.000000  44387.000000  44387.000000  44387.000000  44387.000000   \n",
       "mean      15.834873      8.134595     15.333992     28.851623     65.045491   \n",
       "std        8.642332      3.828660      3.146533     17.527958     26.372867   \n",
       "min        1.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "25%        8.000000      5.000000     13.000000     14.000000     51.000000   \n",
       "50%       16.000000     10.000000     15.000000     29.000000     60.000000   \n",
       "75%       23.000000     11.000000     18.000000     44.000000     74.000000   \n",
       "max       31.000000     12.000000     23.000000     59.000000   1083.000000   \n",
       "\n",
       "           lrscale3  \n",
       "count  44387.000000  \n",
       "mean       1.139996  \n",
       "std        0.837439  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        2.000000  \n",
       "max        2.000000  \n",
       "\n",
       "[8 rows x 124 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sliced.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-109kHtqFcX"
   },
   "source": [
    "How many ppl participated per country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "-GqLZW5q3GXy",
    "outputId": "00ef82a6-7caa-49ad-9f03-0f4c002c3b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name\n",
      "cntry      \n",
      "AT     2010\n",
      "BE     1766\n",
      "CH     1525\n",
      "CZ     2269\n",
      "DE     2852\n",
      "EE     2019\n",
      "ES     1958\n",
      "FI     1925\n",
      "FR     2070\n",
      "GB     1959\n",
      "HU     1614\n",
      "IE     2757\n",
      "IL     2557\n",
      "IS      880\n",
      "IT     2626\n",
      "LT     2122\n",
      "NL     1681\n",
      "NO     1545\n",
      "PL     1694\n",
      "PT     1270\n",
      "RU     2430\n",
      "SE     1551\n",
      "SI     1307\n"
     ]
    }
   ],
   "source": [
    "peoplePerCountry = countries.count() \n",
    "print(peoplePerCountry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "i9F1sXCj3GX1",
    "outputId": "bc0d383f-1f0b-467a-b471-10394c4faa21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a33748710>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "peoplePerCountry.plot.bar(rot=0, fontsize=8, width=0.9, figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Hiihh5LttDt"
   },
   "source": [
    "Total number of participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "O5lfdPvx3GX3",
    "outputId": "cb8acbf2-9d4e-4cd0-f35b-0a5a8eda4ba3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44387"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in total: \n",
    "peoplePerCountry['name'].sum() #44387 people took participation in the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZZ-o2go3GX5"
   },
   "outputs": [],
   "source": [
    "# filter for germany and poland from ALL the data :\n",
    "dataPL = data[ data['cntry'] == 'PL']\n",
    "dataGE = data[ data['cntry'] == 'GE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YKnWTf_j3GX7"
   },
   "outputs": [],
   "source": [
    "#we choose our label to be column = that asks whether a person is defining themselves as right or left wing:\n",
    "# column - lrscale - discrete values from 0 to 10 (ten meaning right) \n",
    "# only take into consideration 1 to 9 - the rest skew the data (10 Better place to live,77 Refusal,88 Don't know, 99 NA)\n",
    "#OR  - take mean which should be around 5:\n",
    "\n",
    "#data['happy'] = data['happy'].replace([77,88,99], 5, inplace=True) <- not working, dunno how to do it\n",
    "#print(data[['happy','cntry']])\n",
    "happiness = data[['happy','cntry']].groupby('cntry')\n",
    "HappinessPerCountry = happiness.mean() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "12Wagzgo3GX8",
    "outputId": "cd1a4fed-1a54-463e-e8e7-9bac74914e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          happy\n",
      "cntry          \n",
      "AT     7.884577\n",
      "BE     7.792752\n",
      "CH     8.280000\n",
      "CZ     7.068312\n",
      "DE     7.833100\n",
      "EE     7.437841\n",
      "ES     7.940756\n",
      "FI     8.269091\n",
      "FR     7.286473\n",
      "GB     7.671771\n",
      "HU     6.989467\n",
      "IE     7.535727\n",
      "IL     8.492374\n",
      "IS     8.315909\n",
      "IT     7.474105\n",
      "LT     7.913761\n",
      "NL     8.009518\n",
      "NO     8.157282\n",
      "PL     9.640496\n",
      "PT     7.479528\n",
      "RU     7.378601\n",
      "SE     8.292070\n",
      "SI     7.758225\n"
     ]
    }
   ],
   "source": [
    "print(HappinessPerCountry) #has anything besides values fro 0 -10 and if they do apply use mean happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "SFKO8Mnd3GYB",
    "outputId": "72d70cd7-606a-47ec-9804-a2b3b4743600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        atchctr\n",
      "cntry          \n",
      "AT     8.107463\n",
      "BE     6.638165\n",
      "CH     8.041967\n",
      "CZ     7.955046\n",
      "DE     7.636746\n",
      "EE     8.176325\n",
      "ES     8.245148\n",
      "FI     8.638961\n",
      "FR     8.185990\n",
      "GB     7.352731\n",
      "HU     8.656134\n",
      "IE     7.958651\n",
      "IL     8.935862\n",
      "IS     8.406818\n",
      "IT     8.293602\n",
      "LT     9.368992\n",
      "NL     7.281975\n",
      "NO     8.369579\n",
      "PL     8.961039\n",
      "PT     8.762205\n",
      "RU     8.659671\n",
      "SE     8.298517\n",
      "SI     7.820199\n"
     ]
    }
   ],
   "source": [
    "attatchmentToCountry = data[['atchctr','cntry']].groupby('cntry')\n",
    "print(attatchmentToCountry.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HkDFiw_GsneP"
   },
   "source": [
    "### Correlation features with political orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "MlTWC80_u0xP",
    "outputId": "a715bfd9-e936-4fa8-c616-539b89e79420"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEDCAYAAAAcI05xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAPcElEQVR4nO3dbYxc5XnG8evKrsN7QhtvIhfTLiUo2EUijqYuBClKDaqAOCFfaEBKFCEkq1KaQoRESZuEulKlfGiCIzWN5BJe2hA7hhAVI4eCAohGAsIskBSyVDjEAdfb7CBk41QBs/bdDzO21+tZ71l8zpx7Zv4/ydqZZ47OfT+7O5fPnrdxRAgAkNc76m4AAHBsBDUAJEdQA0ByBDUAJEdQA0ByBDUAJFdZUNu+zfa07ecKLPv7th+x/Yztn9m+vKq+AKDfVLlFfYekSwsu+yVJWyJilaSrJP1zVU0BQL+pLKgj4jFJr80es3227QdsT9j+T9vnHlxc0rs6j98taVdVfQFAvxntcb2Nkv4iIl60/SdqbzmvkfR3kh60/XlJp0i6pMd9AUBaPQtq26dK+rCku20fHD6h8/VqSXdExNdsXyjp32yfFxEHetUfAGTVyy3qd0jaHREf7PLatersz46Ix22fKGmppOke9gcAKfXs9LyIeF3SL21fKUluO7/z8suSLu6Mr5B0oqRWr3oDgMxc1d3zbG+S9FG1t4x/LelmSQ9L+pakZZKWSNocEX9ve6Wkf5F0qtoHFm+MiAcraQwA+kxlQQ0AKAdXJgJAcpUcTFy6dGmMj49XsWoAGEgTExOvRsRYt9cqCerx8XE1m80qVg0AA8n2r+Z7jV0fAJAcQQ0AyRHUAJAcQQ0AyRHUAJBcr++eV8jkuSuOGlvxwuRA1h2mufZL3TJ77If59nPNYambbou62+SPNd7PdYdprv1St8we+2G+/VxzmOqmC2oAwJEIagBIjqAGgOQIagBILl1Qz3fUtOqjuHXUHaa59kvdMnvsh/n2c81hqlvJ/agbjUZwUyYAKM72REQ0ur2WbosaAHAkghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiv0CS+2d0jaK2m/pJn5LnMEAJRvMR/F9acR8WplnQAAumLXBwAkVzSoQ9KDtidsr+u2gO11tpu2m61Wq7wOAWDIFQ3qiyLiQ5Iuk/Q52x+Zu0BEbIyIRkQ0xsbGSm0SAIZZoaCOiF2dr9OSfiBpdZVNAQAOWzCobZ9i+7SDjyX9maTnqm4MANBW5KyP90n6ge2Dy383Ih6otCsAwCELBnVEvCTp/B70AgDogtPzACA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASA5ghoAkiOoASC5wkFte8T2M7bvr7IhAMCRFrNFfZ2kyaoaAQB0VyiobS+X9DFJt1bbDgBgrqJb1Bsk3SjpwHwL2F5nu2m72Wq1SmkOAFAgqG2vlTQdERPHWi4iNkZEIyIaY2NjpTUIAMOuyBb1RZI+YXuHpM2S1tj+TqVdAQAOWTCoI+KLEbE8IsYlXSXp4Yj4dOWdAQAkcR41AKQ3upiFI+JRSY9W0gkAoCu2qAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJJbMKhtn2j7J7Z/avt52+t70RgAoG20wDJvSloTEb+xvUTSj23/MCKeqLg3AIAKBHVEhKTfdJ4u6fyLKpsCABxWaB+17RHbz0qalvRQRDzZZZl1tpu2m61Wq+w+AWBoFQrqiNgfER+UtFzSatvndVlmY0Q0IqIxNjZWdp8AMLQWddZHROyW9KikSyvpBgBwlCJnfYzZPr3z+CRJl0h6oerGAABtRc76WCbpTtsjagf7loi4v9q2AAAHFTnr42eSVvWgFwBAF1yZCADJEdQAkBxBDQDJEdQAkBxBDQDJEdQAkBxBDQDJEdQAkBxBDQDJEdQAkBxBDQDJEdQAkBxBDQDJEdQAkBxBDQDJEdQAkBxBDQDJEdQAkBxBDQDJEdQAkBxBDQDJEdQAkBxBDQDJEdQAkBxBDQDJEdQAkNyCQW37TNuP2J60/bzt63rRGACgbbTAMjOSboiIp22fJmnC9kMR8fOKewMAqMAWdURMRcTTncd7JU1KOqPqxgAAbYvaR217XNIqSU92eW2d7abtZqvVKqc7AEDxoLZ9qqTvS7o+Il6f+3pEbIyIRkQ0xsbGyuwRAIZaoaC2vUTtkL4rIu6ttiUAwGxFzvqwpG9LmoyIr1ffEgBgtiJb1BdJ+oykNbaf7fy7vOK+AAAdC56eFxE/luQe9AIA6IIrEwEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJJbMKht32Z72vZzvWgIAHCk0QLL3CHpnyT9a7WtHDZ57oqjxla8MDmQdYdprnXU7VavF3WPVX9Q6w7TXHtdd8Et6oh4TNJrlVTvYr431rHecP1ad5jmWkfdhdY7aPOts+4wzbWOuuyjBoDkSgtq2+tsN203W61WWasFgKFXWlBHxMaIaEREY2xsrKzVAsDQY9cHACRX5PS8TZIel/QB2zttX1tlQ/MdNa36KG4ddYdprnXUXWi9gzbfOusO01zrqOuIKH2ljUYjms1m6esFgEFleyIiGt1eY9cHACRHUANAcgQ1ACRHUANAcgQ1ACRX5KZMPbdn61ZN37JBM1NTGl22TO/9wvV698c/PpB1d1xzjX77+BOHnp904QUav/32SmtK0va1a/XW9l8cer7k/Wfr/fffX3ndyT86T9q///DAyIhWPF/9jRnnu4FO1f0Mww2DDqrrd2pq/Xrt3nJ3++c4MqLT//xKLbv55srr9lK6Leo9W7dq6stf0cyuXVKEZnbt0tSXv6I9W7cOXN25IS1Jv338Ce245prKakpHv6Ek6a3tv9D2tWsrrXtUKErS/v3t8SrrHusGOhX2Myw3DJLq+52aWr9euzdtPvxz3L9fuzdt1tT69ZXW7bV0QT19ywbFG28cMRZvvKHpWzYMXN25Ib3QeFnmvqEWGi/N3FBcaLwu2frpA3X9Tu3ecveixvtVuqCemZpa1Hi/1wVwHPrlP//jlG4f9eiyZe3dD13GB7EugOMwMtI9lEdGKi89+cerpb17Dw+cdppWPPWTSmql26L2ySctarwsM7O/4QXGAQyvo0JakvbubY9XIF1Q17b/dL5AJqiBvOra9dHjvEgX1ACAIxHUAJAcQQ0AyRHUAJAcQQ0AyeUL6hNOWNx4v9cF0H96nBf5gnpmZnHjZXnzzcWNA6jffBe2VHzBy+h73rOo8eOVL6iH5JJQACWoKS96fcuJfEENzLJn61a9uOZiTa5YqRfXXFz5XRSBQub7UPAKPixcSnivD+CgPVu3atdf3yQdOCBJmtm1q/1c6sn9yYEs2KJGWlN/+6VDIX3IgQPtcWCIENRIK/btW9Q4MKgIagBIjqAGgOQIagBIrtBZH7YvlfQNSSOSbo2Ir1bZ1Lbzzz5q7PKfVnw/6prqDtNc307dbstL0rZPrdUN37tfX/tUgQ9PnWcdx7Kty3pv+N7hT9Q+nroZv8/9WnNY6i64RW17RNI3JV0maaWkq22vrKQbHeON+TbebNnrDtNc307dhfopFJYlOljveOtm+z73a81hqltk18dqSdsj4qWI2Cdps6QrKukGAHCUIkF9hqRXZj3f2Rk7gu11tpu2m61Wq6z+AGDoFQlqdxk76jrJiNgYEY2IaIyNjR1/ZwAAScWCeqekM2c9Xy5pVzXtAADmKhLUT0k6x/ZZtt8p6SpJ91XV0Owj60XG+7nuMM317dRdqJ+q+52v3vHWzfZ97teaw1TXUeBuT7Yvl7RB7dPzbouIfzjW8o1GI5rNZjkdAsAQsD0REY1urxU6jzoitknaVmpXAIBCuDIRAJIjqAEgOYIaAJIjqAEgOYIaAJIjqAEgOYIaAJIrdMHLoldqtyT9qoRVLZX0agnr6QfDNFeJ+Q6yYZqrVN58/yAiut4oqZKgLovt5nxX6gyaYZqrxHwH2TDNVerNfNn1AQDJEdQAkFz2oN5YdwM9NExzlZjvIBumuUo9mG/qfdQAgPxb1AAw9AhqAEguZVDbvtT2f9vebvumuvupku0zbT9ie9L287avq7unqtkesf2M7d5+REsNbJ9u+x7bL3R+xhfW3VOVbH+h83v8nO1Ntk+su6cy2b7N9rTt52aN/a7th2y/2Pn6O2XXTRfUtkckfVPSZZJWSrra9sp6u6rUjKQbImKFpAskfW7A5ytJ10marLuJHvmGpAci4lxJ52uA5237DEl/JakREeep/YlQV9XbVenukHTpnLGbJP0oIs6R9KPO81KlC2pJqyVtj4iXImKfpM2Srqi5p8pExFREPN15vFftN/IZ9XZVHdvLJX1M0q1191I12++S9BFJ35akiNgXEbvr7apyo5JOsj0q6WQN2AdhR8Rjkl6bM3yFpDs7j++U9Mmy62YM6jMkvTLr+U4NcHDNZntc0ipJT9bbSaU2SLpR0oG6G+mBP5TUknR7Z1fPrbZPqbupqkTE/0j6R0kvS5qStCciHqy3q554X0RMSe0NL0nvLbtAxqB2l7GBP4fQ9qmSvi/p+oh4ve5+qmB7raTpiJiou5ceGZX0IUnfiohVkv5PFfxZnEVn3+wVks6S9HuSTrH96Xq7GgwZg3qnpDNnPV+uAfvzaS7bS9QO6bsi4t66+6nQRZI+YXuH2ru01tj+Tr0tVWqnpJ0RcfAvpHvUDu5BdYmkX0ZEKyLeknSvpA/X3FMv/Nr2MknqfJ0uu0DGoH5K0jm2z7L9TrUPRtxXc0+VsW2192FORsTX6+6nShHxxYhYHhHjav9cH46Igd3iioj/lfSK7Q90hi6W9PMaW6ray5IusH1y5/f6Yg3wwdNZ7pP02c7jz0r697ILjJa9wuMVETO2/1LSf6h91Pi2iHi+5raqdJGkz0j6L9vPdsb+JiK21dgTyvN5SXd1NjpeknRNzf1UJiKetH2PpKfVPpvpGQ3Y5eS2N0n6qKSltndKulnSVyVtsX2t2v9ZXVl6XS4hB4DcMu76AADMQlADQHIENQAkR1ADQHIENQAkR1ADQHIENQAk9/+USCvVn47P9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for column in data_sliced.columns:\n",
    "  if(column != 'cntry'):\n",
    "    x = data_sliced['lrscale']\n",
    "    y = data_sliced[column]\n",
    "    plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any algorithm based on recursive partitioning, such as decision trees, and regression trees does not require inputs (features) to be normalized, since it is invariant to monotonic transformations of the features (just think about how the splits are done at each node). Therefore, thee is no need to use normalization for the classification part of out project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xg9bbHJ1vijo"
   },
   "source": [
    "# Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-g6jRow4vmUD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LA75YLRvmI4h"
   },
   "source": [
    "# PDA AND K-MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "Q2N29jKd3GYE",
    "outputId": "36fa881d-f8c4-4c28-8540-a5f6ad33c541"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Select the cpuntry you want to use\\ndf_country = dataSliced.loc[dataSliced['cntry'] == 'DE']\\n#Seelct columns you want to use\\ndf_sliced = df_country[['pplhlp','trstplt','stflife','imwbcnt','rlgdgr','lkredcc' ]]\\nprint(df_sliced.head(3))\\n\\n#Normalized columns by using max, eventually move to start with data cleaning\\n#ignore the SettingWithCopyWarning\\ndf_sliced['pplhlp'] = df_sliced['pplhlp'] / max(df_sliced['pplhlp'])\\ndf_sliced['trstplt'] = df_sliced['trstplt'] / max(df_sliced['trstplt'])\\ndf_sliced['stflife'] = df_sliced['stflife'] / max(df_sliced['stflife'])\\ndf_sliced['imwbcnt'] = df_sliced['imwbcnt'] / max(df_sliced['imwbcnt'])\\ndf_sliced['rlgdgr'] = df_sliced['rlgdgr'] / max(df_sliced['rlgdgr'])\\ndf_sliced['lkredcc'] = df_sliced['lkredcc'] / max(df_sliced['lkredcc'])\\n#print(df_sliced.head(3))\\n\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Select the cpuntry you want to use\n",
    "df_country = data_sliced.loc[data_sliced['cntry'] == 'DE']\n",
    "#Seelct columns you want to use\n",
    "df_sliced = df_country[['pplhlp','trstplt','stflife','imwbcnt','rlgdgr','lkredcc' ]]\n",
    "print(df_sliced.head(3))\n",
    "\n",
    "#Normalized columns by using max, eventually move to start with data cleaning\n",
    "#ignore the SettingWithCopyWarning\n",
    "df_sliced['pplhlp'] = df_sliced['pplhlp'] / max(df_sliced['pplhlp'])\n",
    "df_sliced['trstplt'] = df_sliced['trstplt'] / max(df_sliced['trstplt'])\n",
    "df_sliced['stflife'] = df_sliced['stflife'] / max(df_sliced['stflife'])\n",
    "df_sliced['imwbcnt'] = df_sliced['imwbcnt'] / max(df_sliced['imwbcnt'])\n",
    "df_sliced['rlgdgr'] = df_sliced['rlgdgr'] / max(df_sliced['rlgdgr'])\n",
    "df_sliced['lkredcc'] = df_sliced['lkredcc'] / max(df_sliced['lkredcc'])\n",
    "#print(df_sliced.head(3))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "pcmfU05q3GYH",
    "outputId": "f60c6409-9203-4c18-b6c5-e7d5a6921feb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#KMEANS\\n#Code from GeeksForGeeks https://www.geeksforgeeks.org/multidimensional-data-analysis-in-python/?fbclid=IwAR1QorEHcKwDum7Em5F3ge_S4b6soljPwv74IJJROZ7wSv86z0Q1KS5Av4M\\nclusters = 3\\nkmeans = KMeans(n_clusters = clusters) \\nkmeans.fit(df_sliced) \\n\\npca = PCA(3) #PCA squeezes data into fewer dimensions\\npca.fit(df_sliced) \\npca_data = pd.DataFrame(pca.transform(df_sliced)) \\n\\n# This part is generate different colors, code from GeeksForGeeks\\ncolors = list(zip(*sorted(( \\n                    tuple(mcolors.rgb_to_hsv( \\n                          mcolors.to_rgba(color)[:3])), name) \\n                     for name, color in dict( \\n                            mcolors.BASE_COLORS, **mcolors.CSS4_COLORS \\n                                                      ).items())))[1] \\nskips = math.floor(len(colors[5 : -5])/clusters) \\ncluster_colors = colors[5 : -5 : skips]\\n\\n#This part generates the 3D graph from, code from  GeeksForGeeks\\nfig = plt.figure() \\nax = fig.add_subplot(111, projection = '3d') \\nax.scatter(pca_data[0], pca_data[1], pca_data[2],  \\n           c = list(map(lambda label : cluster_colors[label], \\n                                            kmeans.labels_))) \\nstr_labels = list(map(lambda label:'% s' % label, kmeans.labels_))  \\nlist(map(lambda data1, data2, data3, str_label: \\n        ax.text(data1, data2, data3, s = str_label, size = 0.5, \\n        zorder = 20, color = 'k'), pca_data[0], pca_data[1], \\n        pca_data[2], str_labels)) \\nplt.show()\\n\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#KMEANS\n",
    "#Code from GeeksForGeeks https://www.geeksforgeeks.org/multidimensional-data-analysis-in-python/?fbclid=IwAR1QorEHcKwDum7Em5F3ge_S4b6soljPwv74IJJROZ7wSv86z0Q1KS5Av4M\n",
    "clusters = 3\n",
    "kmeans = KMeans(n_clusters = clusters) \n",
    "kmeans.fit(df_sliced) \n",
    "\n",
    "pca = PCA(3) #PCA squeezes data into fewer dimensions\n",
    "pca.fit(df_sliced) \n",
    "pca_data = pd.DataFrame(pca.transform(df_sliced)) \n",
    "\n",
    "# This part is generate different colors, code from GeeksForGeeks\n",
    "colors = list(zip(*sorted(( \n",
    "                    tuple(mcolors.rgb_to_hsv( \n",
    "                          mcolors.to_rgba(color)[:3])), name) \n",
    "                     for name, color in dict( \n",
    "                            mcolors.BASE_COLORS, **mcolors.CSS4_COLORS \n",
    "                                                      ).items())))[1] \n",
    "skips = math.floor(len(colors[5 : -5])/clusters) \n",
    "cluster_colors = colors[5 : -5 : skips]\n",
    "\n",
    "#This part generates the 3D graph from, code from  GeeksForGeeks\n",
    "fig = plt.figure() \n",
    "ax = fig.add_subplot(111, projection = '3d') \n",
    "ax.scatter(pca_data[0], pca_data[1], pca_data[2],  \n",
    "           c = list(map(lambda label : cluster_colors[label], \n",
    "                                            kmeans.labels_))) \n",
    "str_labels = list(map(lambda label:'% s' % label, kmeans.labels_))  \n",
    "list(map(lambda data1, data2, data3, str_label: \n",
    "        ax.text(data1, data2, data3, s = str_label, size = 0.5, \n",
    "        zorder = 20, color = 'k'), pca_data[0], pca_data[1], \n",
    "        pca_data[2], str_labels)) \n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "ybnZ8rvT3GYJ",
    "outputId": "2acd74cb-a969-4d1b-a3c0-be0d21846e67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#How do people in each cluster stand politically\\ndf_sliced['cluster'] =kmeans.labels_ #create new column to save cluster values\\ndataCountryLRCluster = dataSliced.loc[dataSliced['cntry'] == 'DE'] #take subset of the dataSliced\\ndataCountryLRCluster['cluster'] = df_sliced['cluster'] #give the subset cluser column\\n#just renaiming lables\\ndataCountryLRCluster.loc[dataCountryLRCluster['lrscale3'] == 0, 'lrscale3'] = '0 left'\\ndataCountryLRCluster.loc[dataCountryLRCluster['lrscale3'] == 1, 'lrscale3'] = '1 center'\\ndataCountryLRCluster.loc[dataCountryLRCluster['lrscale3'] == 2, 'lrscale3'] = '2 right'\\ngroupedBy = dataCountryLRCluster.groupby(['cluster', 'lrscale3'])['cluster'].count().unstack('lrscale3').fillna(0)\\ngroupedBy.plot(kind='bar', stacked=True)\\n\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#How do people in each cluster stand politically\n",
    "df_sliced['cluster'] =kmeans.labels_ #create new column to save cluster values\n",
    "dataCountryLRCluster = data_sliced.loc[data_sliced['cntry'] == 'DE'] #take subset of the data_sliced\n",
    "dataCountryLRCluster['cluster'] = df_sliced['cluster'] #give the subset cluser column\n",
    "#just renaiming lables\n",
    "dataCountryLRCluster.loc[dataCountryLRCluster['lrscale3'] == 0, 'lrscale3'] = '0 left'\n",
    "dataCountryLRCluster.loc[dataCountryLRCluster['lrscale3'] == 1, 'lrscale3'] = '1 center'\n",
    "dataCountryLRCluster.loc[dataCountryLRCluster['lrscale3'] == 2, 'lrscale3'] = '2 right'\n",
    "groupedBy = dataCountryLRCluster.groupby(['cluster', 'lrscale3'])['cluster'].count().unstack('lrscale3').fillna(0)\n",
    "groupedBy.plot(kind='bar', stacked=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YNY4oXq-mOtn"
   },
   "source": [
    "# SUPERVISED LEARNING - DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-w_5TVR3GYL"
   },
   "source": [
    "\n",
    "source: https://www.datacamp.com/community/tutorials/decision-tree-classification-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ec7SDo8v3GYL"
   },
   "source": [
    "Attribute selection measures - a heuristic for selecting the splitting criterion that partition data into the best possible manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5V9JKWzL3GYL"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "SKiA7kw23GYN",
    "outputId": "d95d8284-4199-4a51-fa4f-f9cb9ce150b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# group by groups to see which one is the best to create a decision tree (which one is the best indicator our label):\\n#List of columns for group 'Group Politics'\\n#THIS GROUP IS COUNTRY SPECIFIC - NOT APPLICABLE FOR THE WHOLE DATASET\\ndataPolitics = dataInfo.loc[dataInfo['Group']=='Group Politics']\\nnamesListP = dataPolitics['Name'].tolist()\\n#print(namesListP)\\nnamesListP.remove('lrscale')\\n#print(namesListP)\\n\\n# List of columns for group 'Group Climate change' \\ndataClimateChange = dataInfo.loc[dataInfo['Group']=='Group Climate change']\\nnamesListC = dataClimateChange['Name'].tolist() \\n#print(namesListC)\\n\\n# List of columns for group 'Group Subjective well-being, social exclusion, religion, national and ethnic identity' \\ndataWellBeing = dataInfo.loc[dataInfo['Group']=='Group Subjective well-being, social exclusion, religion, national and ethnic identity']\\nnamesListW = dataWellBeing['Name'].tolist() \\n#print(namesListW)\\n\\n# List of columns for group 'Group Welfare attitudes' \\ndataWelfare = dataInfo.loc[dataInfo['Group']=='Group Climate change']\\nnamesListWelfare = dataWelfare['Name'].tolist() \\n#print(namesListWelfare)\\n\\n#list of columns that are not country specific:\\ndataGeneralQuestions = dataInfo.loc[dataInfo['Country_specific']=='no']\\ndataGeneralQuestionsList = dataGeneralQuestions['Name'].tolist()\\n#print(dataGeneralQuestionsList)\\n\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "# group by groups to see which one is the best to create a decision tree (which one is the best indicator our label):\n",
    "#List of columns for group 'Group Politics'\n",
    "#THIS GROUP IS COUNTRY SPECIFIC - NOT APPLICABLE FOR THE WHOLE DATASET\n",
    "dataPolitics = dataInfo.loc[dataInfo['Group']=='Group Politics']\n",
    "namesListP = dataPolitics['Name'].tolist()\n",
    "#print(namesListP)\n",
    "namesListP.remove('lrscale')\n",
    "#print(namesListP)\n",
    "\n",
    "# List of columns for group 'Group Climate change' \n",
    "dataClimateChange = dataInfo.loc[dataInfo['Group']=='Group Climate change']\n",
    "namesListC = dataClimateChange['Name'].tolist() \n",
    "#print(namesListC)\n",
    "\n",
    "# List of columns for group 'Group Subjective well-being, social exclusion, religion, national and ethnic identity' \n",
    "dataWellBeing = dataInfo.loc[dataInfo['Group']=='Group Subjective well-being, social exclusion, religion, national and ethnic identity']\n",
    "namesListW = dataWellBeing['Name'].tolist() \n",
    "#print(namesListW)\n",
    "\n",
    "# List of columns for group 'Group Welfare attitudes' \n",
    "dataWelfare = dataInfo.loc[dataInfo['Group']=='Group Climate change']\n",
    "namesListWelfare = dataWelfare['Name'].tolist() \n",
    "#print(namesListWelfare)\n",
    "\n",
    "#list of columns that are not country specific:\n",
    "dataGeneralQuestions = dataInfo.loc[dataInfo['Country_specific']=='no']\n",
    "dataGeneralQuestionsList = dataGeneralQuestions['Name'].tolist()\n",
    "#print(dataGeneralQuestionsList)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "v0LKmJSn3GYO",
    "outputId": "d157d457-a103-4156-f825-bd5f8ade6da5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#split dataset in features and target variable\\n#for taking all the features from table - not working rn :\\n#I want to select all columns besides the target one - 'lrscale'\\ndata_no_label = data.drop('lrscale', axis=1)\\n#feature_cols = list(data_no_label.columns) # a list of ALL columns names, besides target lrscale)\\n#print(feature_cols)\\n\\n#Take features just from social trust group \\nfeature_cols = ['nwspol','netusoft','netustm','ppltrst','pplfair','pplhlp']\\n#feature_cols = namesListC + namesListWelfare + namesListW \\n\\n#3rd approach - take only columns that are not country specific \\n#feature_cols = dataGeneralQuestionsList\\nx = data[feature_cols]\\ny = data.lrscale # Target variable\\n\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#split dataset in features and target variable\n",
    "#for taking all the features from table - not working rn :\n",
    "#I want to select all columns besides the target one - 'lrscale'\n",
    "data_no_label = data.drop('lrscale', axis=1)\n",
    "#feature_cols = list(data_no_label.columns) # a list of ALL columns names, besides target lrscale)\n",
    "#print(feature_cols)\n",
    "\n",
    "#Take features just from social trust group \n",
    "feature_cols = ['nwspol','netusoft','netustm','ppltrst','pplfair','pplhlp']\n",
    "#feature_cols = namesListC + namesListWelfare + namesListW \n",
    "\n",
    "#3rd approach - take only columns that are not country specific \n",
    "#feature_cols = dataGeneralQuestionsList\n",
    "x = data[feature_cols]\n",
    "y = data.lrscale # Target variable\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "dTkE1rzN3GYQ",
    "outputId": "9bef8748-17f9-48f0-f92f-64c3c18fe78b"
   },
   "outputs": [],
   "source": [
    "# Taking data_sliced that is the whole dataset, with valus 2.0 (including lrscale)  + country label + lrscale3\n",
    "#I want to select all columns besides the target one - 'lrscale'\n",
    "#ERRROr - NOT FOUND IN AXIS - WHYYYYYY\n",
    "data_sliced = data_sliced.drop('lrscale', axis=1) # we don't that anymore - now we use lrscale3 (with only 3 possible values)\n",
    "\n",
    "#Make it for a specific country (uncomment second line below):\n",
    "#df_country_distinct = data_sliced.loc[data_sliced['cntry'] == 'DE'] # change here the country value\n",
    "#data_sliced= df_country_distinct\n",
    "#data_no_label = df_country_distinct.drop('lrscale3', axis=1) \n",
    "\n",
    "#Make it for the whole dataset:\n",
    "\n",
    "#Drop the country variable - we only want numeric values.\n",
    "data_sliced = data_sliced.drop('cntry', axis=1)\n",
    "\n",
    "#Create a data frame without target variable class\n",
    "data_no_label = data_sliced.drop('lrscale3', axis=1)\n",
    "data_sliced = data_sliced.fillna(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "#data_sliced = data_sliced.fillna(5) <- it does not work without this -> which means the function for fillna doesn't work anymore.\n",
    "feature_cols = list(data_no_label.columns) # a list of ALL columns names, besides target lrscale)\n",
    "x = data_sliced[feature_cols] \n",
    "#NORMALIZE \n",
    "#x = preprocessing.normalize(x)# ->: there is no need to normalie for decision tree. It is however essential for k-means.\n",
    "y = data_sliced.lrscale3 # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WN6N-C_83GYV"
   },
   "outputs": [],
   "source": [
    "\n",
    "# splitting into training and test set: \n",
    "x_train, x_test, y_train,  y_test = train_test_split(x, y, test_size=0.1, random_state=1) # 90% training and 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdVECGFR3GYW"
   },
   "outputs": [],
   "source": [
    "#BULDING A MODEL:\n",
    "# Create Decision Tree classifer object\n",
    "#CHANGE PARAMETERS HERE:\n",
    "clf = DecisionTreeClassifier(max_depth=9) # by defaul't uses gini index for measuring the quality of the split\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(x_train,y_train) #fit - Build a decision tree classifier from the training set (X, y).\n",
    "\n",
    "#Predict the response for test dataset\n",
    "#print(x_test)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p5wh3cji3GYY",
    "outputId": "568dcf90-c28b-49c8-fe3b-a04df8f1b073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5140797476909214\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# The best accuracy seen so far : all numeric features, max_depth 9, fill na used only at the end with value 5. Accuracy: 0.5228655102500563\n",
    "# Omitting normalisation process - just filling in with 5  (and all numeric features, max_depth 9) Accuracy:  0.5140797476909214 REALLY close "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-v-yc_b3GYZ"
   },
   "source": [
    "Firstly I did not specify the depth of the tree so the nodes were expanded until all leafes were pure. That was a big overfit and therefpre the acuraccy on the unseen instances was very low (15%).\n",
    "\n",
    "\"Decision-tree learners can create over-complex trees that do not generalise the data well. This is called overfitting. Mechanisms such as pruning (not currently supported), setting the minimum number of samples required at a leaf node or setting the maximum depth of the tree are necessary to avoid this problem.\" Over-fitting is the phenomenon in which the learning system tightly fits the given training data so much that it would be inaccurate in predicting the outcomes of the untrained data. In decision trees, over-fitting occurs when the tree is designed so as to perfectly fit all samples in the training data set. Thus it ends up with branches with strict rules of sparse data. Thus this effects the accuracy when predicting samples that are not part of the training set.\n",
    "\n",
    "TO change that either specify the depth of the tree (after specifying to depth 10 the acuraccy increased significantly ot 30% - but it is still a poor accuracy) Another ways - less dimensions (only chosen columns that make more sense - according to us the questions are very telling)\n",
    "\n",
    "PLOT a TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eR9ceo3O3GYZ",
    "outputId": "d9a37c4d-6ba1-43d0-dde2-0c5b8255f32b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(175.72366415275994, 206.56799999999998, 'X[46] <= 1.5\\nentropy = 0.652\\nsamples = 39948\\nvalue = [11563, 11177, 17208]'),\n",
       " Text(87.73591944801026, 184.824, 'X[134] <= 3.5\\nentropy = 0.626\\nsamples = 5106\\nvalue = [2539, 1206, 1361]'),\n",
       " Text(46.25526315789474, 163.07999999999998, 'X[289] <= 2.5\\nentropy = 0.663\\nsamples = 2157\\nvalue = [787, 611, 759]'),\n",
       " Text(24.20208600770218, 141.336, 'X[123] <= 2.5\\nentropy = 0.65\\nsamples = 1300\\nvalue = [570, 351, 379]'),\n",
       " Text(13.000898587933248, 119.592, 'X[195] <= 3.705\\nentropy = 0.665\\nsamples = 565\\nvalue = [190, 169, 206]'),\n",
       " Text(6.876508344030809, 97.848, 'X[88] <= 3.5\\nentropy = 0.652\\nsamples = 425\\nvalue = [124, 118, 183]'),\n",
       " Text(3.4382541720154043, 76.10399999999998, 'X[65] <= 6.5\\nentropy = 0.663\\nsamples = 337\\nvalue = [110, 100, 127]'),\n",
       " Text(1.7191270860077021, 54.360000000000014, 'X[61] <= 3.5\\nentropy = 0.647\\nsamples = 188\\nvalue = [45, 61, 82]'),\n",
       " Text(0.8595635430038511, 32.615999999999985, 'X[246] <= 39.5\\nentropy = 0.619\\nsamples = 157\\nvalue = [32, 46, 79]'),\n",
       " Text(0.42978177150192554, 10.872000000000014, 'entropy = 0.656\\nsamples = 47\\nvalue = [19, 12, 16]'),\n",
       " Text(1.2893453145057765, 10.872000000000014, 'entropy = 0.562\\nsamples = 110\\nvalue = [13, 34, 63]'),\n",
       " Text(2.578690629011553, 32.615999999999985, 'X[117] <= 7.5\\nentropy = 0.581\\nsamples = 31\\nvalue = [13, 15, 3]'),\n",
       " Text(2.148908857509628, 10.872000000000014, 'entropy = 0.559\\nsamples = 26\\nvalue = [8, 15, 3]'),\n",
       " Text(3.0084724005134786, 10.872000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(5.157381258023106, 54.360000000000014, 'X[94] <= 4.552\\nentropy = 0.65\\nsamples = 149\\nvalue = [65, 39, 45]'),\n",
       " Text(4.297817715019256, 32.615999999999985, 'X[49] <= 5.27\\nentropy = 0.567\\nsamples = 77\\nvalue = [45, 20, 12]'),\n",
       " Text(3.86803594351733, 10.872000000000014, 'entropy = 0.625\\nsamples = 20\\nvalue = [5, 10, 5]'),\n",
       " Text(4.727599486521181, 10.872000000000014, 'entropy = 0.462\\nsamples = 57\\nvalue = [40, 10, 7]'),\n",
       " Text(6.016944801026957, 32.615999999999985, 'X[244] <= 39.5\\nentropy = 0.643\\nsamples = 72\\nvalue = [20, 19, 33]'),\n",
       " Text(5.587163029525032, 10.872000000000014, 'entropy = 0.491\\nsamples = 34\\nvalue = [10, 2, 22]'),\n",
       " Text(6.446726572528883, 10.872000000000014, 'entropy = 0.647\\nsamples = 38\\nvalue = [10, 17, 11]'),\n",
       " Text(10.314762516046212, 76.10399999999998, 'X[287] <= 11020.5\\nentropy = 0.528\\nsamples = 88\\nvalue = [14, 18, 56]'),\n",
       " Text(8.595635430038511, 54.360000000000014, 'X[301] <= 1.5\\nentropy = 0.635\\nsamples = 20\\nvalue = [4, 9, 7]'),\n",
       " Text(7.73607188703466, 32.615999999999985, 'X[159] <= 1.5\\nentropy = 0.219\\nsamples = 8\\nvalue = [1, 7, 0]'),\n",
       " Text(7.306290115532734, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(8.165853658536586, 10.872000000000014, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7, 0]'),\n",
       " Text(9.455198973042362, 32.615999999999985, 'X[107] <= 2.5\\nentropy = 0.569\\nsamples = 12\\nvalue = [3, 2, 7]'),\n",
       " Text(9.025417201540437, 10.872000000000014, 'entropy = 0.219\\nsamples = 8\\nvalue = [0, 1, 7]'),\n",
       " Text(9.884980744544288, 10.872000000000014, 'entropy = 0.375\\nsamples = 4\\nvalue = [3, 1, 0]'),\n",
       " Text(12.033889602053915, 54.360000000000014, 'X[304] <= 4.5\\nentropy = 0.442\\nsamples = 68\\nvalue = [10, 9, 49]'),\n",
       " Text(11.174326059050063, 32.615999999999985, 'X[289] <= 1.5\\nentropy = 0.24\\nsamples = 45\\nvalue = [3, 3, 39]'),\n",
       " Text(10.744544287548138, 10.872000000000014, 'entropy = 0.5\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(11.604107830551989, 10.872000000000014, 'entropy = 0.094\\nsamples = 41\\nvalue = [1, 1, 39]'),\n",
       " Text(12.893453145057766, 32.615999999999985, 'X[17] <= 6.5\\nentropy = 0.65\\nsamples = 23\\nvalue = [7, 6, 10]'),\n",
       " Text(12.46367137355584, 10.872000000000014, 'entropy = 0.598\\nsamples = 19\\nvalue = [3, 6, 10]'),\n",
       " Text(13.323234916559691, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(19.125288831835686, 97.848, 'X[42] <= 2.5\\nentropy = 0.618\\nsamples = 140\\nvalue = [66, 51, 23]'),\n",
       " Text(16.546598202824132, 76.10399999999998, 'X[90] <= 2.5\\nentropy = 0.552\\nsamples = 97\\nvalue = [57, 29, 11]'),\n",
       " Text(15.47214377406932, 54.360000000000014, 'X[93] <= 8.5\\nentropy = 0.504\\nsamples = 81\\nvalue = [53, 19, 9]'),\n",
       " Text(14.612580231065468, 32.615999999999985, 'X[277] <= 2435.5\\nentropy = 0.423\\nsamples = 71\\nvalue = [52, 13, 6]'),\n",
       " Text(14.182798459563543, 10.872000000000014, 'entropy = 0.531\\nsamples = 8\\nvalue = [2, 5, 1]'),\n",
       " Text(15.042362002567394, 10.872000000000014, 'entropy = 0.348\\nsamples = 63\\nvalue = [50, 8, 5]'),\n",
       " Text(16.33170731707317, 32.615999999999985, 'X[50] <= 8.5\\nentropy = 0.54\\nsamples = 10\\nvalue = [1, 6, 3]'),\n",
       " Text(15.901925545571245, 10.872000000000014, 'entropy = 0.245\\nsamples = 7\\nvalue = [0, 6, 1]'),\n",
       " Text(16.761489088575097, 10.872000000000014, 'entropy = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(17.621052631578948, 54.360000000000014, 'X[113] <= 2.5\\nentropy = 0.531\\nsamples = 16\\nvalue = [4, 10, 2]'),\n",
       " Text(17.191270860077022, 32.615999999999985, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(18.050834403080874, 32.615999999999985, 'X[112] <= 3.5\\nentropy = 0.408\\nsamples = 14\\nvalue = [4, 10, 0]'),\n",
       " Text(17.621052631578948, 10.872000000000014, 'entropy = 0.444\\nsamples = 6\\nvalue = [4, 2, 0]'),\n",
       " Text(18.4806161745828, 10.872000000000014, 'entropy = 0.0\\nsamples = 8\\nvalue = [0, 8, 0]'),\n",
       " Text(21.70397946084724, 76.10399999999998, 'X[52] <= 3.5\\nentropy = 0.617\\nsamples = 43\\nvalue = [9, 22, 12]'),\n",
       " Text(20.629525032092424, 54.360000000000014, 'X[302] <= 3.5\\nentropy = 0.656\\nsamples = 24\\nvalue = [7, 7, 10]'),\n",
       " Text(19.769961489088576, 32.615999999999985, 'X[32] <= 7.5\\nentropy = 0.539\\nsamples = 16\\nvalue = [6, 1, 9]'),\n",
       " Text(19.34017971758665, 10.872000000000014, 'entropy = 0.375\\nsamples = 8\\nvalue = [6, 0, 2]'),\n",
       " Text(20.199743260590502, 10.872000000000014, 'entropy = 0.219\\nsamples = 8\\nvalue = [0, 1, 7]'),\n",
       " Text(21.489088575096275, 32.615999999999985, 'X[35] <= 6.5\\nentropy = 0.406\\nsamples = 8\\nvalue = [1, 6, 1]'),\n",
       " Text(21.05930680359435, 10.872000000000014, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(21.9188703465982, 10.872000000000014, 'entropy = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(22.778433889602052, 54.360000000000014, 'X[145] <= 2.0\\nentropy = 0.355\\nsamples = 19\\nvalue = [2, 15, 2]'),\n",
       " Text(22.348652118100127, 32.615999999999985, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(23.208215661103978, 32.615999999999985, 'X[84] <= 4335.0\\nentropy = 0.208\\nsamples = 17\\nvalue = [2, 15, 0]'),\n",
       " Text(22.778433889602052, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(23.637997432605903, 10.872000000000014, 'entropy = 0.0\\nsamples = 15\\nvalue = [0, 15, 0]'),\n",
       " Text(35.40327342747111, 119.592, 'X[28] <= 1.5\\nentropy = 0.616\\nsamples = 735\\nvalue = [380, 182, 173]'),\n",
       " Text(28.68793324775353, 97.848, 'X[16] <= 5.5\\nentropy = 0.443\\nsamples = 183\\nvalue = [131, 34, 18]'),\n",
       " Text(25.57201540436457, 76.10399999999998, 'X[7] <= 0.5\\nentropy = 0.191\\nsamples = 58\\nvalue = [52, 3, 3]'),\n",
       " Text(24.497560975609755, 54.360000000000014, 'X[302] <= 1.5\\nentropy = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(24.06777920410783, 32.615999999999985, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(24.92734274711168, 32.615999999999985, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(26.646469833119383, 54.360000000000014, 'X[308] <= 4.5\\nentropy = 0.104\\nsamples = 55\\nvalue = [52, 2, 1]'),\n",
       " Text(25.78690629011553, 32.615999999999985, 'X[48] <= 3.5\\nentropy = 0.037\\nsamples = 53\\nvalue = [52, 1, 0]'),\n",
       " Text(25.357124518613606, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(26.216688061617457, 10.872000000000014, 'entropy = 0.0\\nsamples = 52\\nvalue = [52, 0, 0]'),\n",
       " Text(27.506033376123234, 32.615999999999985, 'X[292] <= 3.5\\nentropy = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(27.07625160462131, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(27.93581514762516, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(31.80385109114249, 76.10399999999998, 'X[115] <= 2.554\\nentropy = 0.525\\nsamples = 125\\nvalue = [79, 31, 15]'),\n",
       " Text(30.084724005134788, 54.360000000000014, 'X[122] <= 3.5\\nentropy = 0.434\\nsamples = 77\\nvalue = [56, 11, 10]'),\n",
       " Text(29.225160462130937, 32.615999999999985, 'X[19] <= 1.5\\nentropy = 0.346\\nsamples = 68\\nvalue = [54, 9, 5]'),\n",
       " Text(28.79537869062901, 10.872000000000014, 'entropy = 0.32\\nsamples = 5\\nvalue = [1, 4, 0]'),\n",
       " Text(29.654942233632863, 10.872000000000014, 'entropy = 0.28\\nsamples = 63\\nvalue = [53, 5, 5]'),\n",
       " Text(30.94428754813864, 32.615999999999985, 'X[51] <= 6.5\\nentropy = 0.593\\nsamples = 9\\nvalue = [2, 2, 5]'),\n",
       " Text(30.514505776636714, 10.872000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(31.374069319640565, 10.872000000000014, 'entropy = 0.5\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(33.52297817715019, 54.360000000000014, 'X[235] <= 2015.5\\nentropy = 0.586\\nsamples = 48\\nvalue = [23, 20, 5]'),\n",
       " Text(32.66341463414634, 32.615999999999985, 'X[303] <= 1.5\\nentropy = 0.457\\nsamples = 17\\nvalue = [3, 12, 2]'),\n",
       " Text(32.23363286264441, 10.872000000000014, 'entropy = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(33.093196405648264, 10.872000000000014, 'entropy = 0.245\\nsamples = 14\\nvalue = [2, 12, 0]'),\n",
       " Text(34.382541720154045, 32.615999999999985, 'X[30] <= 1.5\\nentropy = 0.508\\nsamples = 31\\nvalue = [20, 8, 3]'),\n",
       " Text(33.952759948652115, 10.872000000000014, 'entropy = 0.111\\nsamples = 17\\nvalue = [16, 0, 1]'),\n",
       " Text(34.81232349165597, 10.872000000000014, 'entropy = 0.571\\nsamples = 14\\nvalue = [4, 8, 2]'),\n",
       " Text(42.1186136071887, 97.848, 'X[40] <= 1.5\\nentropy = 0.646\\nsamples = 552\\nvalue = [249, 148, 155]'),\n",
       " Text(38.6803594351733, 76.10399999999998, 'X[31] <= 5.0\\nentropy = 0.605\\nsamples = 309\\nvalue = [164, 85, 60]'),\n",
       " Text(36.9612323491656, 54.360000000000014, 'X[17] <= 5.5\\nentropy = 0.519\\nsamples = 153\\nvalue = [99, 27, 27]'),\n",
       " Text(36.10166880616175, 32.615999999999985, 'X[105] <= 4.5\\nentropy = 0.396\\nsamples = 99\\nvalue = [75, 14, 10]'),\n",
       " Text(35.67188703465982, 10.872000000000014, 'entropy = 0.334\\nsamples = 92\\nvalue = [74, 10, 8]'),\n",
       " Text(36.53145057766367, 10.872000000000014, 'entropy = 0.571\\nsamples = 7\\nvalue = [1, 4, 2]'),\n",
       " Text(37.82079589216945, 32.615999999999985, 'X[134] <= 2.5\\nentropy = 0.645\\nsamples = 54\\nvalue = [24, 13, 17]'),\n",
       " Text(37.39101412066752, 10.872000000000014, 'entropy = 0.637\\nsamples = 25\\nvalue = [5, 9, 11]'),\n",
       " Text(38.25057766367137, 10.872000000000014, 'entropy = 0.509\\nsamples = 29\\nvalue = [19, 4, 6]'),\n",
       " Text(40.399486521181004, 54.360000000000014, 'X[229] <= 1.5\\nentropy = 0.643\\nsamples = 156\\nvalue = [65, 58, 33]'),\n",
       " Text(39.53992297817715, 32.615999999999985, 'X[157] <= 3.5\\nentropy = 0.414\\nsamples = 31\\nvalue = [23, 5, 3]'),\n",
       " Text(39.11014120667522, 10.872000000000014, 'entropy = 0.309\\nsamples = 28\\nvalue = [23, 2, 3]'),\n",
       " Text(39.969704749679074, 10.872000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(41.25905006418485, 32.615999999999985, 'X[305] <= 3.5\\nentropy = 0.65\\nsamples = 125\\nvalue = [42, 53, 30]'),\n",
       " Text(40.829268292682926, 10.872000000000014, 'entropy = 0.63\\nsamples = 86\\nvalue = [20, 42, 24]'),\n",
       " Text(41.68883183568678, 10.872000000000014, 'entropy = 0.579\\nsamples = 39\\nvalue = [22, 11, 6]'),\n",
       " Text(45.556867779204104, 76.10399999999998, 'X[2] <= 2.004\\nentropy = 0.658\\nsamples = 243\\nvalue = [85, 63, 95]'),\n",
       " Text(43.8377406931964, 54.360000000000014, 'X[3] <= 7.5\\nentropy = 0.628\\nsamples = 148\\nvalue = [39, 36, 73]'),\n",
       " Text(42.97817715019255, 32.615999999999985, 'X[87] <= 1.5\\nentropy = 0.556\\nsamples = 13\\nvalue = [7, 5, 1]'),\n",
       " Text(42.54839537869063, 10.872000000000014, 'entropy = 0.531\\nsamples = 8\\nvalue = [2, 5, 1]'),\n",
       " Text(43.40795892169448, 10.872000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(44.69730423620025, 32.615999999999985, 'X[155] <= 2.5\\nentropy = 0.607\\nsamples = 135\\nvalue = [32, 31, 72]'),\n",
       " Text(44.26752246469833, 10.872000000000014, 'entropy = 0.651\\nsamples = 30\\nvalue = [13, 8, 9]'),\n",
       " Text(45.12708600770218, 10.872000000000014, 'entropy = 0.559\\nsamples = 105\\nvalue = [19, 23, 63]'),\n",
       " Text(47.27599486521181, 54.360000000000014, 'X[14] <= 3.958\\nentropy = 0.631\\nsamples = 95\\nvalue = [46, 27, 22]'),\n",
       " Text(46.416431322207956, 32.615999999999985, 'X[180] <= 1959.5\\nentropy = 0.45\\nsamples = 38\\nvalue = [27, 7, 4]'),\n",
       " Text(45.98664955070603, 10.872000000000014, 'entropy = 0.5\\nsamples = 6\\nvalue = [1, 4, 1]'),\n",
       " Text(46.846213093709885, 10.872000000000014, 'entropy = 0.322\\nsamples = 32\\nvalue = [26, 3, 3]'),\n",
       " Text(48.13555840821566, 32.615999999999985, 'X[203] <= 1.36\\nentropy = 0.666\\nsamples = 57\\nvalue = [19, 20, 18]'),\n",
       " Text(47.705776636713736, 10.872000000000014, 'entropy = 0.627\\nsamples = 35\\nvalue = [14, 6, 15]'),\n",
       " Text(48.56534017971759, 10.872000000000014, 'entropy = 0.525\\nsamples = 22\\nvalue = [5, 14, 3]'),\n",
       " Text(68.30844030808728, 141.336, 'X[14] <= 6.5\\nentropy = 0.647\\nsamples = 857\\nvalue = [217, 260, 380]'),\n",
       " Text(57.16097560975609, 119.592, 'X[157] <= 1.5\\nentropy = 0.66\\nsamples = 534\\nvalue = [144, 191, 199]'),\n",
       " Text(52.433376123234915, 97.848, 'X[282] <= 6.832\\nentropy = 0.539\\nsamples = 71\\nvalue = [10, 17, 44]'),\n",
       " Text(51.14403080872914, 76.10399999999998, 'X[105] <= 4.5\\nentropy = 0.39\\nsamples = 50\\nvalue = [4, 8, 38]'),\n",
       " Text(50.71424903722721, 54.360000000000014, 'X[64] <= 0.5\\nentropy = 0.302\\nsamples = 46\\nvalue = [4, 4, 38]'),\n",
       " Text(49.85468549422336, 32.615999999999985, 'X[213] <= 4.0\\nentropy = 0.628\\nsamples = 11\\nvalue = [4, 2, 5]'),\n",
       " Text(49.42490372272144, 10.872000000000014, 'entropy = 0.571\\nsamples = 7\\nvalue = [4, 2, 1]'),\n",
       " Text(50.28446726572529, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(51.57381258023106, 32.615999999999985, 'X[94] <= 5.653\\nentropy = 0.108\\nsamples = 35\\nvalue = [0, 2, 33]'),\n",
       " Text(51.14403080872914, 10.872000000000014, 'entropy = 0.057\\nsamples = 34\\nvalue = [0, 1, 33]'),\n",
       " Text(52.00359435173299, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(51.57381258023106, 54.360000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(53.722721437740695, 76.10399999999998, 'X[118] <= 4.375\\nentropy = 0.653\\nsamples = 21\\nvalue = [6, 9, 6]'),\n",
       " Text(52.863157894736844, 54.360000000000014, 'X[90] <= 2.5\\nentropy = 0.569\\nsamples = 12\\nvalue = [6, 1, 5]'),\n",
       " Text(52.433376123234915, 32.615999999999985, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(53.292939666238766, 32.615999999999985, 'X[112] <= 3.5\\nentropy = 0.449\\nsamples = 7\\nvalue = [1, 1, 5]'),\n",
       " Text(52.863157894736844, 10.872000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(53.722721437740695, 10.872000000000014, 'entropy = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(54.58228498074455, 54.360000000000014, 'X[117] <= 1.5\\nentropy = 0.198\\nsamples = 9\\nvalue = [0, 8, 1]'),\n",
       " Text(54.15250320924262, 32.615999999999985, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(55.01206675224647, 32.615999999999985, 'entropy = 0.0\\nsamples = 8\\nvalue = [0, 8, 0]'),\n",
       " Text(61.88857509627728, 97.848, 'X[197] <= 4.5\\nentropy = 0.663\\nsamples = 463\\nvalue = [134, 174, 155]'),\n",
       " Text(58.450320924261874, 76.10399999999998, 'X[63] <= 2.094\\nentropy = 0.659\\nsamples = 269\\nvalue = [98, 100, 71]'),\n",
       " Text(56.73119383825417, 54.360000000000014, 'X[168] <= 1.5\\nentropy = 0.549\\nsamples = 56\\nvalue = [33, 17, 6]'),\n",
       " Text(55.87163029525032, 32.615999999999985, 'X[308] <= 1.5\\nentropy = 0.609\\nsamples = 17\\nvalue = [4, 9, 4]'),\n",
       " Text(55.44184852374839, 10.872000000000014, 'entropy = 0.571\\nsamples = 7\\nvalue = [4, 1, 2]'),\n",
       " Text(56.30141206675224, 10.872000000000014, 'entropy = 0.32\\nsamples = 10\\nvalue = [0, 8, 2]'),\n",
       " Text(57.59075738125802, 32.615999999999985, 'X[102] <= 4.5\\nentropy = 0.402\\nsamples = 39\\nvalue = [29, 8, 2]'),\n",
       " Text(57.16097560975609, 10.872000000000014, 'entropy = 0.264\\nsamples = 33\\nvalue = [28, 4, 1]'),\n",
       " Text(58.020539152759945, 10.872000000000014, 'entropy = 0.5\\nsamples = 6\\nvalue = [1, 4, 1]'),\n",
       " Text(60.169448010269576, 54.360000000000014, 'X[132] <= 1.5\\nentropy = 0.662\\nsamples = 213\\nvalue = [65, 83, 65]'),\n",
       " Text(59.309884467265725, 32.615999999999985, 'X[84] <= 2006.0\\nentropy = 0.438\\nsamples = 18\\nvalue = [13, 2, 3]'),\n",
       " Text(58.880102695763796, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(59.73966623876765, 10.872000000000014, 'entropy = 0.305\\nsamples = 16\\nvalue = [13, 0, 3]'),\n",
       " Text(61.02901155327343, 32.615999999999985, 'X[27] <= 1.5\\nentropy = 0.655\\nsamples = 195\\nvalue = [52, 81, 62]'),\n",
       " Text(60.5992297817715, 10.872000000000014, 'entropy = 0.594\\nsamples = 35\\nvalue = [19, 10, 6]'),\n",
       " Text(61.45879332477535, 10.872000000000014, 'entropy = 0.638\\nsamples = 160\\nvalue = [33, 71, 56]'),\n",
       " Text(65.32682926829268, 76.10399999999998, 'X[191] <= 2.5\\nentropy = 0.633\\nsamples = 194\\nvalue = [36, 74, 84]'),\n",
       " Text(63.60770218228498, 54.360000000000014, 'X[322] <= 50.5\\nentropy = 0.639\\nsamples = 148\\nvalue = [30, 64, 54]'),\n",
       " Text(62.74813863928113, 32.615999999999985, 'X[9] <= 2.5\\nentropy = 0.611\\nsamples = 126\\nvalue = [19, 60, 47]'),\n",
       " Text(62.3183568677792, 10.872000000000014, 'entropy = 0.547\\nsamples = 54\\nvalue = [8, 33, 13]'),\n",
       " Text(63.17792041078305, 10.872000000000014, 'entropy = 0.613\\nsamples = 72\\nvalue = [11, 27, 34]'),\n",
       " Text(64.46726572528883, 32.615999999999985, 'X[37] <= 3.5\\nentropy = 0.616\\nsamples = 22\\nvalue = [11, 4, 7]'),\n",
       " Text(64.0374839537869, 10.872000000000014, 'entropy = 0.298\\nsamples = 11\\nvalue = [9, 2, 0]'),\n",
       " Text(64.89704749679076, 10.872000000000014, 'entropy = 0.529\\nsamples = 11\\nvalue = [2, 2, 7]'),\n",
       " Text(67.04595635430039, 54.360000000000014, 'X[36] <= 4.5\\nentropy = 0.51\\nsamples = 46\\nvalue = [6, 10, 30]'),\n",
       " Text(66.18639281129653, 32.615999999999985, 'X[20] <= 3.5\\nentropy = 0.568\\nsamples = 9\\nvalue = [3, 5, 1]'),\n",
       " Text(65.7566110397946, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(66.61617458279846, 10.872000000000014, 'entropy = 0.56\\nsamples = 5\\nvalue = [3, 1, 1]'),\n",
       " Text(67.90551989730423, 32.615999999999985, 'X[1] <= 3.176\\nentropy = 0.361\\nsamples = 37\\nvalue = [3, 5, 29]'),\n",
       " Text(67.47573812580231, 10.872000000000014, 'entropy = 0.258\\nsamples = 34\\nvalue = [1, 4, 29]'),\n",
       " Text(68.33530166880617, 10.872000000000014, 'entropy = 0.444\\nsamples = 3\\nvalue = [2, 1, 0]'),\n",
       " Text(79.45590500641849, 119.592, 'X[247] <= 74.5\\nentropy = 0.589\\nsamples = 323\\nvalue = [73, 69, 181]'),\n",
       " Text(73.2777920410783, 97.848, 'X[313] <= 4.5\\nentropy = 0.494\\nsamples = 156\\nvalue = [26, 25, 105]'),\n",
       " Text(70.91399229781771, 76.10399999999998, 'X[30] <= 1.5\\nentropy = 0.649\\nsamples = 21\\nvalue = [7, 9, 5]'),\n",
       " Text(70.05442875481386, 54.360000000000014, 'X[135] <= 2.5\\nentropy = 0.592\\nsamples = 13\\nvalue = [7, 2, 4]'),\n",
       " Text(69.62464698331193, 32.615999999999985, 'X[64] <= 0.5\\nentropy = 0.444\\nsamples = 6\\nvalue = [0, 2, 4]'),\n",
       " Text(69.19486521181001, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(70.05442875481386, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(70.48421052631579, 32.615999999999985, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0, 0]'),\n",
       " Text(71.77355584082156, 54.360000000000014, 'X[140] <= 6.0\\nentropy = 0.219\\nsamples = 8\\nvalue = [0, 7, 1]'),\n",
       " Text(71.34377406931964, 32.615999999999985, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7, 0]'),\n",
       " Text(72.2033376123235, 32.615999999999985, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(75.6415917843389, 76.10399999999998, 'X[53] <= 2.5\\nentropy = 0.417\\nsamples = 135\\nvalue = [19, 16, 100]'),\n",
       " Text(73.9224646983312, 54.360000000000014, 'X[92] <= 4.5\\nentropy = 0.606\\nsamples = 43\\nvalue = [10, 10, 23]'),\n",
       " Text(73.06290115532734, 32.615999999999985, 'X[219] <= 0.5\\nentropy = 0.427\\nsamples = 30\\nvalue = [4, 4, 22]'),\n",
       " Text(72.63311938382542, 10.872000000000014, 'entropy = 0.313\\nsamples = 27\\nvalue = [1, 4, 22]'),\n",
       " Text(73.49268292682926, 10.872000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(74.78202824133504, 32.615999999999985, 'X[119] <= 5.5\\nentropy = 0.568\\nsamples = 13\\nvalue = [6, 6, 1]'),\n",
       " Text(74.35224646983312, 10.872000000000014, 'entropy = 0.406\\nsamples = 8\\nvalue = [1, 6, 1]'),\n",
       " Text(75.21181001283696, 10.872000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(77.3607188703466, 54.360000000000014, 'X[215] <= 317.0\\nentropy = 0.286\\nsamples = 92\\nvalue = [9, 6, 77]'),\n",
       " Text(76.50115532734274, 32.615999999999985, 'X[160] <= 35.976\\nentropy = 0.538\\nsamples = 28\\nvalue = [8, 3, 17]'),\n",
       " Text(76.07137355584082, 10.872000000000014, 'entropy = 0.455\\nsamples = 24\\nvalue = [4, 3, 17]'),\n",
       " Text(76.93093709884467, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(78.22028241335045, 32.615999999999985, 'X[32] <= 2.5\\nentropy = 0.119\\nsamples = 64\\nvalue = [1, 3, 60]'),\n",
       " Text(77.79050064184852, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(78.65006418485237, 10.872000000000014, 'entropy = 0.091\\nsamples = 63\\nvalue = [0, 3, 60]'),\n",
       " Text(85.63401797175867, 97.848, 'X[299] <= 3.5\\nentropy = 0.644\\nsamples = 167\\nvalue = [47, 44, 76]'),\n",
       " Text(82.5181001283697, 76.10399999999998, 'X[107] <= 1.5\\nentropy = 0.642\\nsamples = 123\\nvalue = [27, 42, 54]'),\n",
       " Text(80.79897304236201, 54.360000000000014, 'X[132] <= 3.5\\nentropy = 0.438\\nsamples = 18\\nvalue = [3, 13, 2]'),\n",
       " Text(79.93940949935815, 32.615999999999985, 'X[180] <= 1997.5\\nentropy = 0.231\\nsamples = 15\\nvalue = [2, 13, 0]'),\n",
       " Text(79.50962772785623, 10.872000000000014, 'entropy = 0.0\\nsamples = 13\\nvalue = [0, 13, 0]'),\n",
       " Text(80.36919127086007, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(81.65853658536585, 32.615999999999985, 'X[102] <= 2.0\\nentropy = 0.444\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(81.22875481386393, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(82.08831835686777, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(84.2372272143774, 54.360000000000014, 'X[196] <= 3.361\\nentropy = 0.626\\nsamples = 105\\nvalue = [24, 29, 52]'),\n",
       " Text(83.37766367137355, 32.615999999999985, 'X[58] <= 9.5\\nentropy = 0.567\\nsamples = 74\\nvalue = [20, 11, 43]'),\n",
       " Text(82.94788189987163, 10.872000000000014, 'entropy = 0.627\\nsamples = 53\\nvalue = [18, 10, 25]'),\n",
       " Text(83.80744544287548, 10.872000000000014, 'entropy = 0.254\\nsamples = 21\\nvalue = [2, 1, 18]'),\n",
       " Text(85.09679075738126, 32.615999999999985, 'X[5] <= 135.0\\nentropy = 0.562\\nsamples = 31\\nvalue = [4, 18, 9]'),\n",
       " Text(84.66700898587933, 10.872000000000014, 'entropy = 0.397\\nsamples = 11\\nvalue = [0, 3, 8]'),\n",
       " Text(85.52657252888318, 10.872000000000014, 'entropy = 0.395\\nsamples = 20\\nvalue = [4, 15, 1]'),\n",
       " Text(88.74993581514762, 76.10399999999998, 'X[126] <= 5.5\\nentropy = 0.541\\nsamples = 44\\nvalue = [20, 2, 22]'),\n",
       " Text(87.6754813863928, 54.360000000000014, 'X[39] <= 4.5\\nentropy = 0.475\\nsamples = 22\\nvalue = [15, 2, 5]'),\n",
       " Text(86.81591784338896, 32.615999999999985, 'X[298] <= 1.5\\nentropy = 0.449\\nsamples = 7\\nvalue = [1, 1, 5]'),\n",
       " Text(86.38613607188704, 10.872000000000014, 'entropy = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(87.24569961489088, 10.872000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(88.53504492939666, 32.615999999999985, 'X[132] <= 1.5\\nentropy = 0.124\\nsamples = 15\\nvalue = [14, 1, 0]'),\n",
       " Text(88.10526315789474, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(88.96482670089858, 10.872000000000014, 'entropy = 0.0\\nsamples = 14\\nvalue = [14, 0, 0]'),\n",
       " Text(89.82439024390244, 54.360000000000014, 'X[59] <= 8.5\\nentropy = 0.351\\nsamples = 22\\nvalue = [5, 0, 17]'),\n",
       " Text(89.3946084724005, 32.615999999999985, 'entropy = 0.0\\nsamples = 15\\nvalue = [0, 0, 15]'),\n",
       " Text(90.25417201540436, 32.615999999999985, 'X[295] <= 3.5\\nentropy = 0.408\\nsamples = 7\\nvalue = [5, 0, 2]'),\n",
       " Text(89.82439024390244, 10.872000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(90.68395378690629, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(129.2165757381258, 163.07999999999998, 'X[30] <= 1.5\\nentropy = 0.565\\nsamples = 2949\\nvalue = [1752, 595, 602]'),\n",
       " Text(112.2267650834403, 141.336, 'X[42] <= 2.5\\nentropy = 0.469\\nsamples = 1713\\nvalue = [1193, 239, 281]'),\n",
       " Text(101.96572528883183, 119.592, 'X[123] <= 2.5\\nentropy = 0.4\\nsamples = 1401\\nvalue = [1058, 160, 183]'),\n",
       " Text(95.62644415917843, 97.848, 'X[2] <= 0.528\\nentropy = 0.578\\nsamples = 356\\nvalue = [203, 60, 93]'),\n",
       " Text(93.26264441591785, 76.10399999999998, 'X[8] <= 9.5\\nentropy = 0.589\\nsamples = 188\\nvalue = [92, 21, 75]'),\n",
       " Text(92.83286264441591, 54.360000000000014, 'X[135] <= 2.5\\nentropy = 0.572\\nsamples = 183\\nvalue = [92, 16, 75]'),\n",
       " Text(91.97329910141207, 32.615999999999985, 'X[125] <= 9.5\\nentropy = 0.555\\nsamples = 40\\nvalue = [10, 6, 24]'),\n",
       " Text(91.54351732991015, 10.872000000000014, 'entropy = 0.5\\nsamples = 37\\nvalue = [10, 3, 24]'),\n",
       " Text(92.40308087291399, 10.872000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(93.69242618741977, 32.615999999999985, 'X[289] <= 2.5\\nentropy = 0.539\\nsamples = 143\\nvalue = [82, 10, 51]'),\n",
       " Text(93.26264441591785, 10.872000000000014, 'entropy = 0.346\\nsamples = 45\\nvalue = [35, 0, 10]'),\n",
       " Text(94.12220795892169, 10.872000000000014, 'entropy = 0.585\\nsamples = 98\\nvalue = [47, 10, 41]'),\n",
       " Text(93.69242618741977, 54.360000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
       " Text(97.99024390243902, 76.10399999999998, 'X[178] <= 70.5\\nentropy = 0.498\\nsamples = 168\\nvalue = [111, 39, 18]'),\n",
       " Text(96.27111681643132, 54.360000000000014, 'X[131] <= 3.5\\nentropy = 0.451\\nsamples = 154\\nvalue = [108, 35, 11]'),\n",
       " Text(95.41155327342747, 32.615999999999985, 'X[58] <= 7.5\\nentropy = 0.592\\nsamples = 52\\nvalue = [27, 18, 7]'),\n",
       " Text(94.98177150192555, 10.872000000000014, 'entropy = 0.265\\nsamples = 20\\nvalue = [17, 2, 1]'),\n",
       " Text(95.8413350449294, 10.872000000000014, 'entropy = 0.617\\nsamples = 32\\nvalue = [10, 16, 6]'),\n",
       " Text(97.13068035943517, 32.615999999999985, 'X[246] <= 777.0\\nentropy = 0.34\\nsamples = 102\\nvalue = [81, 17, 4]'),\n",
       " Text(96.70089858793324, 10.872000000000014, 'entropy = 0.315\\nsamples = 100\\nvalue = [81, 17, 2]'),\n",
       " Text(97.5604621309371, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(99.70937098844672, 54.360000000000014, 'X[313] <= 16.5\\nentropy = 0.622\\nsamples = 14\\nvalue = [3, 4, 7]'),\n",
       " Text(98.84980744544288, 32.615999999999985, 'X[36] <= 0.5\\nentropy = 0.32\\nsamples = 5\\nvalue = [1, 4, 0]'),\n",
       " Text(98.42002567394094, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(99.2795892169448, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(100.56893453145058, 32.615999999999985, 'X[12] <= 2.5\\nentropy = 0.346\\nsamples = 9\\nvalue = [2, 0, 7]'),\n",
       " Text(100.13915275994864, 10.872000000000014, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 0, 7]'),\n",
       " Text(100.9987163029525, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(108.30500641848523, 97.848, 'X[38] <= 1.5\\nentropy = 0.314\\nsamples = 1045\\nvalue = [855, 100, 90]'),\n",
       " Text(104.86675224646983, 76.10399999999998, 'X[45] <= 1.5\\nentropy = 0.193\\nsamples = 553\\nvalue = [495, 32, 26]'),\n",
       " Text(103.14762516046213, 54.360000000000014, 'X[88] <= 2.5\\nentropy = 0.159\\nsamples = 519\\nvalue = [475, 26, 18]'),\n",
       " Text(102.28806161745828, 32.615999999999985, 'X[36] <= 9.5\\nentropy = 0.112\\nsamples = 461\\nvalue = [434, 17, 10]'),\n",
       " Text(101.85827984595635, 10.872000000000014, 'entropy = 0.101\\nsamples = 457\\nvalue = [433, 15, 9]'),\n",
       " Text(102.7178433889602, 10.872000000000014, 'entropy = 0.625\\nsamples = 4\\nvalue = [1, 2, 1]'),\n",
       " Text(104.00718870346599, 32.615999999999985, 'X[280] <= 660.0\\nentropy = 0.457\\nsamples = 58\\nvalue = [41, 9, 8]'),\n",
       " Text(103.57740693196405, 10.872000000000014, 'entropy = 0.399\\nsamples = 53\\nvalue = [40, 5, 8]'),\n",
       " Text(104.43697047496791, 10.872000000000014, 'entropy = 0.32\\nsamples = 5\\nvalue = [1, 4, 0]'),\n",
       " Text(106.58587933247753, 54.360000000000014, 'X[64] <= 5.5\\nentropy = 0.567\\nsamples = 34\\nvalue = [20, 6, 8]'),\n",
       " Text(105.72631578947369, 32.615999999999985, 'X[91] <= 6.5\\nentropy = 0.39\\nsamples = 25\\nvalue = [19, 4, 2]'),\n",
       " Text(105.29653401797175, 10.872000000000014, 'entropy = 0.48\\nsamples = 5\\nvalue = [0, 3, 2]'),\n",
       " Text(106.15609756097561, 10.872000000000014, 'entropy = 0.095\\nsamples = 20\\nvalue = [19, 1, 0]'),\n",
       " Text(107.44544287548139, 32.615999999999985, 'X[115] <= 1.5\\nentropy = 0.494\\nsamples = 9\\nvalue = [1, 2, 6]'),\n",
       " Text(107.01566110397945, 10.872000000000014, 'entropy = 0.444\\nsamples = 3\\nvalue = [1, 2, 0]'),\n",
       " Text(107.87522464698331, 10.872000000000014, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(111.74326059050064, 76.10399999999998, 'X[7] <= 3.5\\nentropy = 0.429\\nsamples = 492\\nvalue = [360, 68, 64]'),\n",
       " Text(110.02413350449294, 54.360000000000014, 'X[309] <= 3.5\\nentropy = 0.667\\nsamples = 27\\nvalue = [9, 9, 9]'),\n",
       " Text(109.1645699614891, 32.615999999999985, 'X[317] <= 5.5\\nentropy = 0.547\\nsamples = 17\\nvalue = [1, 9, 7]'),\n",
       " Text(108.73478818998716, 10.872000000000014, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7, 0]'),\n",
       " Text(109.59435173299102, 10.872000000000014, 'entropy = 0.46\\nsamples = 10\\nvalue = [1, 2, 7]'),\n",
       " Text(110.88369704749678, 32.615999999999985, 'X[317] <= 48.5\\nentropy = 0.32\\nsamples = 10\\nvalue = [8, 0, 2]'),\n",
       " Text(110.45391527599486, 10.872000000000014, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0, 0]'),\n",
       " Text(111.31347881899872, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(113.46238767650834, 54.360000000000014, 'X[2] <= 0.125\\nentropy = 0.4\\nsamples = 465\\nvalue = [351, 59, 55]'),\n",
       " Text(112.60282413350448, 32.615999999999985, 'X[88] <= 1.5\\nentropy = 0.591\\nsamples = 36\\nvalue = [17, 4, 15]'),\n",
       " Text(112.17304236200256, 10.872000000000014, 'entropy = 0.18\\nsamples = 10\\nvalue = [9, 0, 1]'),\n",
       " Text(113.03260590500642, 10.872000000000014, 'entropy = 0.592\\nsamples = 26\\nvalue = [8, 4, 14]'),\n",
       " Text(114.32195121951219, 32.615999999999985, 'X[242] <= 8.5\\nentropy = 0.369\\nsamples = 429\\nvalue = [334, 55, 40]'),\n",
       " Text(113.89216944801026, 10.872000000000014, 'entropy = 0.266\\nsamples = 273\\nvalue = [232, 24, 17]'),\n",
       " Text(114.75173299101412, 10.872000000000014, 'entropy = 0.511\\nsamples = 156\\nvalue = [102, 31, 23]'),\n",
       " Text(122.48780487804878, 119.592, 'X[38] <= 2.5\\nentropy = 0.65\\nsamples = 312\\nvalue = [135, 79, 98]'),\n",
       " Text(118.72721437740692, 97.848, 'X[90] <= 2.5\\nentropy = 0.621\\nsamples = 229\\nvalue = [116, 54, 59]'),\n",
       " Text(116.68575096277279, 76.10399999999998, 'X[41] <= 1.5\\nentropy = 0.577\\nsamples = 182\\nvalue = [105, 42, 35]'),\n",
       " Text(115.61129653401797, 54.360000000000014, 'X[99] <= 2.5\\nentropy = 0.463\\nsamples = 11\\nvalue = [0, 7, 4]'),\n",
       " Text(115.18151476251604, 32.615999999999985, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7, 0]'),\n",
       " Text(116.04107830551989, 32.615999999999985, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(117.76020539152759, 54.360000000000014, 'X[60] <= 1.5\\nentropy = 0.548\\nsamples = 171\\nvalue = [105, 35, 31]'),\n",
       " Text(116.90064184852375, 32.615999999999985, 'X[243] <= 6.033\\nentropy = 0.619\\nsamples = 112\\nvalue = [57, 30, 25]'),\n",
       " Text(116.47086007702183, 10.872000000000014, 'entropy = 0.664\\nsamples = 62\\nvalue = [23, 20, 19]'),\n",
       " Text(117.33042362002567, 10.872000000000014, 'entropy = 0.483\\nsamples = 50\\nvalue = [34, 10, 6]'),\n",
       " Text(118.61976893453145, 32.615999999999985, 'X[243] <= 7.5\\nentropy = 0.321\\nsamples = 59\\nvalue = [48, 5, 6]'),\n",
       " Text(118.18998716302953, 10.872000000000014, 'entropy = 0.09\\nsamples = 43\\nvalue = [41, 1, 1]'),\n",
       " Text(119.04955070603337, 10.872000000000014, 'entropy = 0.648\\nsamples = 16\\nvalue = [7, 4, 5]'),\n",
       " Text(120.76867779204107, 76.10399999999998, 'X[143] <= 2.5\\nentropy = 0.619\\nsamples = 47\\nvalue = [11, 12, 24]'),\n",
       " Text(120.33889602053915, 54.360000000000014, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(121.198459563543, 54.360000000000014, 'X[192] <= 2.293\\nentropy = 0.564\\nsamples = 41\\nvalue = [11, 6, 24]'),\n",
       " Text(120.33889602053915, 32.615999999999985, 'X[248] <= 3.759\\nentropy = 0.544\\nsamples = 13\\nvalue = [8, 2, 3]'),\n",
       " Text(119.90911424903723, 10.872000000000014, 'entropy = 0.375\\nsamples = 4\\nvalue = [0, 1, 3]'),\n",
       " Text(120.76867779204107, 10.872000000000014, 'entropy = 0.198\\nsamples = 9\\nvalue = [8, 1, 0]'),\n",
       " Text(122.05802310654686, 32.615999999999985, 'X[152] <= 3.0\\nentropy = 0.406\\nsamples = 28\\nvalue = [3, 4, 21]'),\n",
       " Text(121.62824133504493, 10.872000000000014, 'entropy = 0.444\\nsamples = 3\\nvalue = [1, 2, 0]'),\n",
       " Text(122.48780487804878, 10.872000000000014, 'entropy = 0.282\\nsamples = 25\\nvalue = [2, 2, 21]'),\n",
       " Text(126.24839537869063, 97.848, 'X[190] <= 3335.5\\nentropy = 0.636\\nsamples = 83\\nvalue = [19, 25, 39]'),\n",
       " Text(124.42182284980744, 76.10399999999998, 'X[49] <= 3.793\\nentropy = 0.589\\nsamples = 70\\nvalue = [13, 18, 39]'),\n",
       " Text(123.34736842105264, 54.360000000000014, 'X[40] <= 1.5\\nentropy = 0.278\\nsamples = 6\\nvalue = [5, 0, 1]'),\n",
       " Text(122.9175866495507, 32.615999999999985, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(123.77715019255456, 32.615999999999985, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(125.49627727856226, 54.360000000000014, 'X[313] <= 19.5\\nentropy = 0.553\\nsamples = 64\\nvalue = [8, 18, 38]'),\n",
       " Text(124.6367137355584, 32.615999999999985, 'X[252] <= 1.5\\nentropy = 0.413\\nsamples = 39\\nvalue = [4, 6, 29]'),\n",
       " Text(124.20693196405648, 10.872000000000014, 'entropy = 0.611\\nsamples = 6\\nvalue = [2, 3, 1]'),\n",
       " Text(125.06649550706032, 10.872000000000014, 'entropy = 0.268\\nsamples = 33\\nvalue = [2, 3, 28]'),\n",
       " Text(126.3558408215661, 32.615999999999985, 'X[312] <= 2715.0\\nentropy = 0.614\\nsamples = 25\\nvalue = [4, 12, 9]'),\n",
       " Text(125.92605905006418, 10.872000000000014, 'entropy = 0.406\\nsamples = 16\\nvalue = [2, 12, 2]'),\n",
       " Text(126.78562259306803, 10.872000000000014, 'entropy = 0.346\\nsamples = 9\\nvalue = [2, 0, 7]'),\n",
       " Text(128.0749679075738, 76.10399999999998, 'X[248] <= 3.5\\nentropy = 0.497\\nsamples = 13\\nvalue = [6, 7, 0]'),\n",
       " Text(127.64518613607189, 54.360000000000014, 'X[113] <= 1.0\\nentropy = 0.245\\nsamples = 7\\nvalue = [6, 1, 0]'),\n",
       " Text(127.21540436456996, 32.615999999999985, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(128.0749679075738, 32.615999999999985, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(128.50474967907573, 54.360000000000014, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(146.20638639281128, 141.336, 'X[289] <= 2.5\\nentropy = 0.645\\nsamples = 1236\\nvalue = [559, 356, 321]'),\n",
       " Text(136.93921694480102, 119.592, 'X[27] <= 1.5\\nentropy = 0.598\\nsamples = 739\\nvalue = [397, 214, 128]'),\n",
       " Text(131.7281129653402, 97.848, 'X[66] <= 1.5\\nentropy = 0.32\\nsamples = 122\\nvalue = [99, 17, 6]'),\n",
       " Text(129.79409499358152, 76.10399999999998, 'X[161] <= 1.5\\nentropy = 0.556\\nsamples = 13\\nvalue = [5, 7, 1]'),\n",
       " Text(129.36431322207957, 54.360000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(130.22387676508345, 54.360000000000014, 'X[155] <= 6.0\\nentropy = 0.37\\nsamples = 9\\nvalue = [1, 7, 1]'),\n",
       " Text(129.79409499358152, 32.615999999999985, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7, 0]'),\n",
       " Text(130.65365853658537, 32.615999999999985, 'X[260] <= 0.5\\nentropy = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(130.22387676508345, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(131.0834403080873, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(133.66213093709885, 76.10399999999998, 'X[45] <= 1.5\\nentropy = 0.246\\nsamples = 109\\nvalue = [94, 10, 5]'),\n",
       " Text(132.80256739409498, 54.360000000000014, 'X[33] <= 9.5\\nentropy = 0.152\\nsamples = 98\\nvalue = [90, 6, 2]'),\n",
       " Text(132.37278562259306, 32.615999999999985, 'X[154] <= 6.0\\nentropy = 0.119\\nsamples = 96\\nvalue = [90, 4, 2]'),\n",
       " Text(131.94300385109113, 10.872000000000014, 'entropy = 0.082\\nsamples = 94\\nvalue = [90, 3, 1]'),\n",
       " Text(132.80256739409498, 10.872000000000014, 'entropy = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(133.23234916559693, 32.615999999999985, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(134.5216944801027, 54.360000000000014, 'X[64] <= 3.0\\nentropy = 0.661\\nsamples = 11\\nvalue = [4, 4, 3]'),\n",
       " Text(134.09191270860077, 32.615999999999985, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(134.95147625160462, 32.615999999999985, 'X[321] <= 14.0\\nentropy = 0.49\\nsamples = 7\\nvalue = [0, 4, 3]'),\n",
       " Text(134.5216944801027, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(135.38125802310654, 10.872000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(142.15032092426188, 97.848, 'X[198] <= 3.833\\nentropy = 0.626\\nsamples = 617\\nvalue = [298, 197, 122]'),\n",
       " Text(139.24929396662387, 76.10399999999998, 'X[52] <= 2.993\\nentropy = 0.662\\nsamples = 138\\nvalue = [41, 43, 54]'),\n",
       " Text(137.53016688061618, 54.360000000000014, 'X[246] <= 55.5\\nentropy = 0.48\\nsamples = 51\\nvalue = [8, 8, 35]'),\n",
       " Text(136.67060333761233, 32.615999999999985, 'X[127] <= 2.5\\nentropy = 0.642\\nsamples = 26\\nvalue = [7, 7, 12]'),\n",
       " Text(136.24082156611038, 10.872000000000014, 'entropy = 0.498\\nsamples = 15\\nvalue = [7, 0, 8]'),\n",
       " Text(137.10038510911426, 10.872000000000014, 'entropy = 0.463\\nsamples = 11\\nvalue = [0, 7, 4]'),\n",
       " Text(138.38973042362002, 32.615999999999985, 'X[36] <= 8.5\\nentropy = 0.15\\nsamples = 25\\nvalue = [1, 1, 23]'),\n",
       " Text(137.9599486521181, 10.872000000000014, 'entropy = 0.0\\nsamples = 23\\nvalue = [0, 0, 23]'),\n",
       " Text(138.81951219512194, 10.872000000000014, 'entropy = 0.5\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(140.96842105263158, 54.360000000000014, 'X[312] <= 2041.5\\nentropy = 0.647\\nsamples = 87\\nvalue = [33, 35, 19]'),\n",
       " Text(140.1088575096277, 32.615999999999985, 'X[3] <= 1107.5\\nentropy = 0.523\\nsamples = 39\\nvalue = [8, 25, 6]'),\n",
       " Text(139.6790757381258, 10.872000000000014, 'entropy = 0.434\\nsamples = 35\\nvalue = [8, 25, 2]'),\n",
       " Text(140.53863928112966, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(141.82798459563543, 32.615999999999985, 'X[39] <= 4.5\\nentropy = 0.612\\nsamples = 48\\nvalue = [25, 10, 13]'),\n",
       " Text(141.3982028241335, 10.872000000000014, 'entropy = 0.551\\nsamples = 15\\nvalue = [4, 2, 9]'),\n",
       " Text(142.25776636713735, 10.872000000000014, 'entropy = 0.522\\nsamples = 33\\nvalue = [21, 8, 4]'),\n",
       " Text(145.05134788189986, 76.10399999999998, 'X[135] <= 2.5\\nentropy = 0.589\\nsamples = 479\\nvalue = [257, 154, 68]'),\n",
       " Text(143.97689345314507, 54.360000000000014, 'X[154] <= 6.0\\nentropy = 0.639\\nsamples = 130\\nvalue = [49, 55, 26]'),\n",
       " Text(143.54711168164312, 32.615999999999985, 'X[129] <= 8.5\\nentropy = 0.639\\nsamples = 123\\nvalue = [42, 55, 26]'),\n",
       " Text(143.1173299101412, 10.872000000000014, 'entropy = 0.65\\nsamples = 106\\nvalue = [41, 41, 24]'),\n",
       " Text(143.97689345314507, 10.872000000000014, 'entropy = 0.304\\nsamples = 17\\nvalue = [1, 14, 2]'),\n",
       " Text(144.406675224647, 32.615999999999985, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0, 0]'),\n",
       " Text(146.12580231065468, 54.360000000000014, 'X[120] <= 2.5\\nentropy = 0.55\\nsamples = 349\\nvalue = [208, 99, 42]'),\n",
       " Text(145.26623876765083, 32.615999999999985, 'X[313] <= 1.5\\nentropy = 0.452\\nsamples = 172\\nvalue = [121, 37, 14]'),\n",
       " Text(144.8364569961489, 10.872000000000014, 'entropy = 0.278\\nsamples = 6\\nvalue = [1, 5, 0]'),\n",
       " Text(145.69602053915276, 10.872000000000014, 'entropy = 0.433\\nsamples = 166\\nvalue = [120, 32, 14]'),\n",
       " Text(146.98536585365852, 32.615999999999985, 'X[117] <= 4.704\\nentropy = 0.611\\nsamples = 177\\nvalue = [87, 62, 28]'),\n",
       " Text(146.5555840821566, 10.872000000000014, 'entropy = 0.585\\nsamples = 106\\nvalue = [60, 25, 21]'),\n",
       " Text(147.41514762516047, 10.872000000000014, 'entropy = 0.574\\nsamples = 71\\nvalue = [27, 37, 7]'),\n",
       " Text(155.47355584082158, 119.592, 'X[29] <= 1.5\\nentropy = 0.661\\nsamples = 497\\nvalue = [162, 142, 193]'),\n",
       " Text(151.06829268292682, 97.848, 'X[248] <= 3.181\\nentropy = 0.6\\nsamples = 118\\nvalue = [64, 24, 30]'),\n",
       " Text(149.13427471116816, 76.10399999999998, 'X[48] <= 4.783\\nentropy = 0.39\\nsamples = 42\\nvalue = [32, 4, 6]'),\n",
       " Text(148.70449293966624, 54.360000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(149.56405648267008, 54.360000000000014, 'X[194] <= 2.726\\nentropy = 0.31\\nsamples = 39\\nvalue = [32, 4, 3]'),\n",
       " Text(148.70449293966624, 32.615999999999985, 'X[126] <= 5.5\\nentropy = 0.204\\nsamples = 36\\nvalue = [32, 2, 2]'),\n",
       " Text(148.27471116816432, 10.872000000000014, 'entropy = 0.0\\nsamples = 27\\nvalue = [27, 0, 0]'),\n",
       " Text(149.13427471116816, 10.872000000000014, 'entropy = 0.593\\nsamples = 9\\nvalue = [5, 2, 2]'),\n",
       " Text(150.42362002567393, 32.615999999999985, 'X[321] <= 16.5\\nentropy = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(149.993838254172, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(150.85340179717588, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(153.0023106546855, 76.10399999999998, 'X[240] <= 4.0\\nentropy = 0.654\\nsamples = 76\\nvalue = [32, 20, 24]'),\n",
       " Text(152.57252888318357, 54.360000000000014, 'X[154] <= 5.5\\nentropy = 0.638\\nsamples = 71\\nvalue = [32, 15, 24]'),\n",
       " Text(152.14274711168164, 32.615999999999985, 'X[117] <= 5.5\\nentropy = 0.63\\nsamples = 66\\nvalue = [32, 15, 19]'),\n",
       " Text(151.71296534017972, 10.872000000000014, 'entropy = 0.594\\nsamples = 48\\nvalue = [26, 14, 8]'),\n",
       " Text(152.57252888318357, 10.872000000000014, 'entropy = 0.512\\nsamples = 18\\nvalue = [6, 1, 11]'),\n",
       " Text(153.0023106546855, 32.615999999999985, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(153.4320924261874, 54.360000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
       " Text(159.8788189987163, 97.848, 'X[244] <= 43.5\\nentropy = 0.651\\nsamples = 379\\nvalue = [98, 118, 163]'),\n",
       " Text(156.4405648267009, 76.10399999999998, 'X[140] <= 2.5\\nentropy = 0.665\\nsamples = 269\\nvalue = [80, 96, 93]'),\n",
       " Text(154.7214377406932, 54.360000000000014, 'X[64] <= 1.5\\nentropy = 0.609\\nsamples = 108\\nvalue = [15, 49, 44]'),\n",
       " Text(153.86187419768933, 32.615999999999985, 'X[122] <= 1.5\\nentropy = 0.545\\nsamples = 34\\nvalue = [7, 21, 6]'),\n",
       " Text(153.4320924261874, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(154.29165596919125, 10.872000000000014, 'entropy = 0.46\\nsamples = 30\\nvalue = [3, 21, 6]'),\n",
       " Text(155.58100128369705, 32.615999999999985, 'X[244] <= 32.5\\nentropy = 0.581\\nsamples = 74\\nvalue = [8, 28, 38]'),\n",
       " Text(155.15121951219513, 10.872000000000014, 'entropy = 0.426\\nsamples = 18\\nvalue = [1, 13, 4]'),\n",
       " Text(156.01078305519897, 10.872000000000014, 'entropy = 0.544\\nsamples = 56\\nvalue = [7, 15, 34]'),\n",
       " Text(158.1596919127086, 54.360000000000014, 'X[13] <= 2.5\\nentropy = 0.659\\nsamples = 161\\nvalue = [65, 47, 49]'),\n",
       " Text(157.30012836970474, 32.615999999999985, 'X[0] <= 0.517\\nentropy = 0.662\\nsamples = 94\\nvalue = [26, 35, 33]'),\n",
       " Text(156.87034659820281, 10.872000000000014, 'entropy = 0.292\\nsamples = 12\\nvalue = [1, 1, 10]'),\n",
       " Text(157.72991014120666, 10.872000000000014, 'entropy = 0.656\\nsamples = 82\\nvalue = [25, 34, 23]'),\n",
       " Text(159.01925545571245, 32.615999999999985, 'X[129] <= 9.5\\nentropy = 0.572\\nsamples = 67\\nvalue = [39, 12, 16]'),\n",
       " Text(158.58947368421053, 10.872000000000014, 'entropy = 0.483\\nsamples = 55\\nvalue = [37, 5, 13]'),\n",
       " Text(159.44903722721438, 10.872000000000014, 'entropy = 0.569\\nsamples = 12\\nvalue = [2, 7, 3]'),\n",
       " Text(163.3170731707317, 76.10399999999998, 'X[129] <= 5.5\\nentropy = 0.528\\nsamples = 110\\nvalue = [18, 22, 70]'),\n",
       " Text(161.59794608472401, 54.360000000000014, 'X[313] <= 17.5\\nentropy = 0.667\\nsamples = 33\\nvalue = [11, 11, 11]'),\n",
       " Text(160.73838254172014, 32.615999999999985, 'X[104] <= 4.5\\nentropy = 0.512\\nsamples = 18\\nvalue = [11, 1, 6]'),\n",
       " Text(160.30860077021822, 10.872000000000014, 'entropy = 0.418\\nsamples = 15\\nvalue = [11, 1, 3]'),\n",
       " Text(161.16816431322206, 10.872000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(162.45750962772786, 32.615999999999985, 'X[52] <= 2.084\\nentropy = 0.444\\nsamples = 15\\nvalue = [0, 10, 5]'),\n",
       " Text(162.02772785622594, 10.872000000000014, 'entropy = 0.0\\nsamples = 8\\nvalue = [0, 8, 0]'),\n",
       " Text(162.88729139922978, 10.872000000000014, 'entropy = 0.408\\nsamples = 7\\nvalue = [0, 2, 5]'),\n",
       " Text(165.0362002567394, 54.360000000000014, 'X[323] <= 39.5\\nentropy = 0.384\\nsamples = 77\\nvalue = [7, 11, 59]'),\n",
       " Text(164.17663671373555, 32.615999999999985, 'X[294] <= 4.0\\nentropy = 0.444\\nsamples = 6\\nvalue = [0, 4, 2]'),\n",
       " Text(163.74685494223363, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(164.60641848523747, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(165.89576379974326, 32.615999999999985, 'X[256] <= 9.5\\nentropy = 0.336\\nsamples = 71\\nvalue = [7, 7, 57]'),\n",
       " Text(165.46598202824134, 10.872000000000014, 'entropy = 0.284\\nsamples = 68\\nvalue = [5, 6, 57]'),\n",
       " Text(166.3255455712452, 10.872000000000014, 'entropy = 0.444\\nsamples = 3\\nvalue = [2, 1, 0]'),\n",
       " Text(263.71140885750964, 184.824, 'X[195] <= 3.705\\nentropy = 0.644\\nsamples = 34842\\nvalue = [9024, 9971, 15847]'),\n",
       " Text(220.53177150192553, 163.07999999999998, 'X[188] <= 4340.5\\nentropy = 0.633\\nsamples = 30459\\nvalue = [7326, 8440, 14693]'),\n",
       " Text(194.26136071887035, 141.336, 'X[31] <= 3.5\\nentropy = 0.65\\nsamples = 19992\\nvalue = [5137, 6160, 8695]'),\n",
       " Text(180.50834403080873, 119.592, 'X[38] <= 2.5\\nentropy = 0.637\\nsamples = 8674\\nvalue = [2677, 1965, 4032]'),\n",
       " Text(173.63183568677792, 97.848, 'X[134] <= 3.5\\nentropy = 0.651\\nsamples = 5860\\nvalue = [2158, 1358, 2344]'),\n",
       " Text(170.1935815147625, 76.10399999999998, 'X[64] <= 2.672\\nentropy = 0.641\\nsamples = 3367\\nvalue = [983, 834, 1550]'),\n",
       " Text(168.4744544287548, 54.360000000000014, 'X[88] <= 3.5\\nentropy = 0.648\\nsamples = 905\\nvalue = [361, 201, 343]'),\n",
       " Text(167.61489088575095, 32.615999999999985, 'X[48] <= 6.182\\nentropy = 0.633\\nsamples = 508\\nvalue = [242, 114, 152]'),\n",
       " Text(167.18510911424903, 10.872000000000014, 'entropy = 0.66\\nsamples = 304\\nvalue = [114, 81, 109]'),\n",
       " Text(168.04467265725287, 10.872000000000014, 'entropy = 0.536\\nsamples = 204\\nvalue = [128, 33, 43]'),\n",
       " Text(169.33401797175867, 32.615999999999985, 'X[195] <= 3.54\\nentropy = 0.631\\nsamples = 397\\nvalue = [119, 87, 191]'),\n",
       " Text(168.90423620025675, 10.872000000000014, 'entropy = 0.613\\nsamples = 343\\nvalue = [84, 80, 179]'),\n",
       " Text(169.7637997432606, 10.872000000000014, 'entropy = 0.514\\nsamples = 54\\nvalue = [35, 7, 12]'),\n",
       " Text(171.9127086007702, 54.360000000000014, 'X[312] <= 551600992.0\\nentropy = 0.63\\nsamples = 2462\\nvalue = [622, 633, 1207]'),\n",
       " Text(171.05314505776636, 32.615999999999985, 'X[46] <= 2.5\\nentropy = 0.626\\nsamples = 2334\\nvalue = [609, 564, 1161]'),\n",
       " Text(170.62336328626444, 10.872000000000014, 'entropy = 0.645\\nsamples = 1082\\nvalue = [349, 255, 478]'),\n",
       " Text(171.48292682926828, 10.872000000000014, 'entropy = 0.598\\nsamples = 1252\\nvalue = [260, 309, 683]'),\n",
       " Text(172.77227214377407, 32.615999999999985, 'X[256] <= 5.029\\nentropy = 0.57\\nsamples = 128\\nvalue = [13, 69, 46]'),\n",
       " Text(172.34249037227215, 10.872000000000014, 'entropy = 0.516\\nsamples = 84\\nvalue = [10, 54, 20]'),\n",
       " Text(173.202053915276, 10.872000000000014, 'entropy = 0.53\\nsamples = 44\\nvalue = [3, 15, 26]'),\n",
       " Text(177.07008985879332, 76.10399999999998, 'X[42] <= 3.5\\nentropy = 0.632\\nsamples = 2493\\nvalue = [1175, 524, 794]'),\n",
       " Text(175.3509627727856, 54.360000000000014, 'X[88] <= 3.5\\nentropy = 0.591\\nsamples = 1540\\nvalue = [855, 299, 386]'),\n",
       " Text(174.49139922978176, 32.615999999999985, 'X[309] <= 3.5\\nentropy = 0.544\\nsamples = 1121\\nvalue = [694, 204, 223]'),\n",
       " Text(174.06161745827984, 10.872000000000014, 'entropy = 0.602\\nsamples = 692\\nvalue = [374, 151, 167]'),\n",
       " Text(174.92118100128368, 10.872000000000014, 'entropy = 0.411\\nsamples = 429\\nvalue = [320, 53, 56]'),\n",
       " Text(176.21052631578948, 32.615999999999985, 'X[34] <= 5.5\\nentropy = 0.65\\nsamples = 419\\nvalue = [161, 95, 163]'),\n",
       " Text(175.78074454428756, 10.872000000000014, 'entropy = 0.644\\nsamples = 289\\nvalue = [129, 68, 92]'),\n",
       " Text(176.6403080872914, 10.872000000000014, 'entropy = 0.598\\nsamples = 130\\nvalue = [32, 27, 71]'),\n",
       " Text(178.789216944801, 54.360000000000014, 'X[195] <= 3.54\\nentropy = 0.648\\nsamples = 953\\nvalue = [320, 225, 408]'),\n",
       " Text(177.92965340179717, 32.615999999999985, 'X[34] <= 4.357\\nentropy = 0.645\\nsamples = 851\\nvalue = [251, 215, 385]'),\n",
       " Text(177.49987163029525, 10.872000000000014, 'entropy = 0.657\\nsamples = 389\\nvalue = [145, 98, 146]'),\n",
       " Text(178.3594351732991, 10.872000000000014, 'entropy = 0.616\\nsamples = 462\\nvalue = [106, 117, 239]'),\n",
       " Text(179.64878048780488, 32.615999999999985, 'X[179] <= 1976.5\\nentropy = 0.482\\nsamples = 102\\nvalue = [69, 10, 23]'),\n",
       " Text(179.21899871630293, 10.872000000000014, 'entropy = 0.39\\nsamples = 80\\nvalue = [61, 9, 10]'),\n",
       " Text(180.0785622593068, 10.872000000000014, 'entropy = 0.517\\nsamples = 22\\nvalue = [8, 1, 13]'),\n",
       " Text(187.38485237483954, 97.848, 'X[242] <= 7.198\\nentropy = 0.56\\nsamples = 2814\\nvalue = [519, 607, 1688]'),\n",
       " Text(183.94659820282413, 76.10399999999998, 'X[123] <= 2.5\\nentropy = 0.619\\nsamples = 1262\\nvalue = [306, 311, 645]'),\n",
       " Text(182.22747111681642, 54.360000000000014, 'X[87] <= 1.5\\nentropy = 0.579\\nsamples = 737\\nvalue = [151, 162, 424]'),\n",
       " Text(181.36790757381257, 32.615999999999985, 'X[235] <= 8332.5\\nentropy = 0.554\\nsamples = 644\\nvalue = [121, 132, 391]'),\n",
       " Text(180.93812580231065, 10.872000000000014, 'entropy = 0.548\\nsamples = 635\\nvalue = [114, 131, 390]'),\n",
       " Text(181.7976893453145, 10.872000000000014, 'entropy = 0.37\\nsamples = 9\\nvalue = [7, 1, 1]'),\n",
       " Text(183.0870346598203, 32.615999999999985, 'X[312] <= 3653.5\\nentropy = 0.666\\nsamples = 93\\nvalue = [30, 30, 33]'),\n",
       " Text(182.65725288831834, 10.872000000000014, 'entropy = 0.62\\nsamples = 63\\nvalue = [25, 10, 28]'),\n",
       " Text(183.5168164313222, 10.872000000000014, 'entropy = 0.5\\nsamples = 30\\nvalue = [5, 20, 5]'),\n",
       " Text(185.66572528883182, 54.360000000000014, 'X[34] <= 4.836\\nentropy = 0.655\\nsamples = 525\\nvalue = [155, 149, 221]'),\n",
       " Text(184.80616174582798, 32.615999999999985, 'X[208] <= 5.089\\nentropy = 0.658\\nsamples = 194\\nvalue = [79, 55, 60]'),\n",
       " Text(184.37637997432606, 10.872000000000014, 'entropy = 0.64\\nsamples = 73\\nvalue = [19, 20, 34]'),\n",
       " Text(185.2359435173299, 10.872000000000014, 'entropy = 0.624\\nsamples = 121\\nvalue = [60, 35, 26]'),\n",
       " Text(186.5252888318357, 32.615999999999985, 'X[0] <= 0.759\\nentropy = 0.63\\nsamples = 331\\nvalue = [76, 94, 161]'),\n",
       " Text(186.09550706033374, 10.872000000000014, 'entropy = 0.647\\nsamples = 76\\nvalue = [20, 34, 22]'),\n",
       " Text(186.95507060333762, 10.872000000000014, 'entropy = 0.599\\nsamples = 255\\nvalue = [56, 60, 139]'),\n",
       " Text(190.82310654685494, 76.10399999999998, 'X[256] <= 5.385\\nentropy = 0.493\\nsamples = 1552\\nvalue = [213, 296, 1043]'),\n",
       " Text(189.10397946084723, 54.360000000000014, 'X[126] <= 5.5\\nentropy = 0.577\\nsamples = 614\\nvalue = [109, 152, 353]'),\n",
       " Text(188.24441591784338, 32.615999999999985, 'X[61] <= 2.647\\nentropy = 0.631\\nsamples = 321\\nvalue = [71, 96, 154]'),\n",
       " Text(187.81463414634146, 10.872000000000014, 'entropy = 0.612\\nsamples = 256\\nvalue = [58, 64, 134]'),\n",
       " Text(188.6741976893453, 10.872000000000014, 'entropy = 0.623\\nsamples = 65\\nvalue = [13, 32, 20]'),\n",
       " Text(189.9635430038511, 32.615999999999985, 'X[88] <= 3.5\\nentropy = 0.485\\nsamples = 293\\nvalue = [38, 56, 199]'),\n",
       " Text(189.53376123234915, 10.872000000000014, 'entropy = 0.561\\nsamples = 178\\nvalue = [30, 42, 106]'),\n",
       " Text(190.39332477535302, 10.872000000000014, 'entropy = 0.326\\nsamples = 115\\nvalue = [8, 14, 93]'),\n",
       " Text(192.54223363286263, 54.360000000000014, 'X[312] <= 13104.0\\nentropy = 0.423\\nsamples = 938\\nvalue = [104, 144, 690]'),\n",
       " Text(191.6826700898588, 32.615999999999985, 'X[124] <= 3.5\\nentropy = 0.38\\nsamples = 754\\nvalue = [76, 97, 581]'),\n",
       " Text(191.25288831835687, 10.872000000000014, 'entropy = 0.449\\nsamples = 478\\nvalue = [59, 78, 341]'),\n",
       " Text(192.1124518613607, 10.872000000000014, 'entropy = 0.235\\nsamples = 276\\nvalue = [17, 19, 240]'),\n",
       " Text(193.40179717586648, 32.615999999999985, 'X[40] <= 1.5\\nentropy = 0.561\\nsamples = 184\\nvalue = [28, 47, 109]'),\n",
       " Text(192.97201540436456, 10.872000000000014, 'entropy = 0.658\\nsamples = 69\\nvalue = [19, 22, 28]'),\n",
       " Text(193.83157894736843, 10.872000000000014, 'entropy = 0.451\\nsamples = 115\\nvalue = [9, 25, 81]'),\n",
       " Text(208.01437740693197, 119.592, 'X[289] <= 2.5\\nentropy = 0.646\\nsamples = 11318\\nvalue = [2460, 4195, 4663]'),\n",
       " Text(201.13786906290116, 97.848, 'X[195] <= 2.859\\nentropy = 0.66\\nsamples = 4954\\nvalue = [1413, 1965, 1576]'),\n",
       " Text(197.69961489088575, 76.10399999999998, 'X[162] <= 1.5\\nentropy = 0.642\\nsamples = 2305\\nvalue = [477, 889, 939]'),\n",
       " Text(195.98048780487804, 54.360000000000014, 'X[48] <= 7.5\\nentropy = 0.65\\nsamples = 1152\\nvalue = [291, 498, 363]'),\n",
       " Text(195.1209242618742, 32.615999999999985, 'X[283] <= 471.5\\nentropy = 0.64\\nsamples = 992\\nvalue = [218, 446, 328]'),\n",
       " Text(194.69114249037227, 10.872000000000014, 'entropy = 0.63\\nsamples = 854\\nvalue = [177, 408, 269]'),\n",
       " Text(195.55070603337612, 10.872000000000014, 'entropy = 0.653\\nsamples = 138\\nvalue = [41, 38, 59]'),\n",
       " Text(196.84005134788188, 32.615999999999985, 'X[115] <= 6.5\\nentropy = 0.638\\nsamples = 160\\nvalue = [73, 52, 35]'),\n",
       " Text(196.41026957637996, 10.872000000000014, 'entropy = 0.618\\nsamples = 147\\nvalue = [72, 49, 26]'),\n",
       " Text(197.26983311938383, 10.872000000000014, 'entropy = 0.462\\nsamples = 13\\nvalue = [1, 3, 9]'),\n",
       " Text(199.41874197689344, 54.360000000000014, 'X[88] <= 3.5\\nentropy = 0.609\\nsamples = 1153\\nvalue = [186, 391, 576]'),\n",
       " Text(198.5591784338896, 32.615999999999985, 'X[34] <= 5.275\\nentropy = 0.639\\nsamples = 608\\nvalue = [126, 216, 266]'),\n",
       " Text(198.12939666238768, 10.872000000000014, 'entropy = 0.656\\nsamples = 377\\nvalue = [95, 146, 136]'),\n",
       " Text(198.98896020539152, 10.872000000000014, 'entropy = 0.573\\nsamples = 231\\nvalue = [31, 70, 130]'),\n",
       " Text(200.2783055198973, 32.615999999999985, 'X[20] <= 4.9\\nentropy = 0.561\\nsamples = 545\\nvalue = [60, 175, 310]'),\n",
       " Text(199.84852374839537, 10.872000000000014, 'entropy = 0.504\\nsamples = 320\\nvalue = [23, 93, 204]'),\n",
       " Text(200.70808729139924, 10.872000000000014, 'entropy = 0.618\\nsamples = 225\\nvalue = [37, 82, 106]'),\n",
       " Text(204.57612323491657, 76.10399999999998, 'X[34] <= 3.66\\nentropy = 0.652\\nsamples = 2649\\nvalue = [936, 1076, 637]'),\n",
       " Text(202.85699614890885, 54.360000000000014, 'X[131] <= 6.0\\nentropy = 0.597\\nsamples = 784\\nvalue = [383, 302, 99]'),\n",
       " Text(201.997432605905, 32.615999999999985, 'X[129] <= 6.574\\nentropy = 0.606\\nsamples = 701\\nvalue = [315, 293, 93]'),\n",
       " Text(201.56765083440308, 10.872000000000014, 'entropy = 0.613\\nsamples = 328\\nvalue = [111, 162, 55]'),\n",
       " Text(202.42721437740693, 10.872000000000014, 'entropy = 0.567\\nsamples = 373\\nvalue = [204, 131, 38]'),\n",
       " Text(203.7165596919127, 32.615999999999985, 'X[282] <= 5.57\\nentropy = 0.312\\nsamples = 83\\nvalue = [68, 9, 6]'),\n",
       " Text(203.28677792041077, 10.872000000000014, 'entropy = 0.5\\nsamples = 10\\nvalue = [5, 0, 5]'),\n",
       " Text(204.14634146341464, 10.872000000000014, 'entropy = 0.24\\nsamples = 73\\nvalue = [63, 9, 1]'),\n",
       " Text(206.29525032092425, 54.360000000000014, 'X[137] <= 1.5\\nentropy = 0.657\\nsamples = 1865\\nvalue = [553, 774, 538]'),\n",
       " Text(205.4356867779204, 32.615999999999985, 'X[88] <= 2.5\\nentropy = 0.581\\nsamples = 159\\nvalue = [91, 35, 33]'),\n",
       " Text(205.0059050064185, 10.872000000000014, 'entropy = 0.48\\nsamples = 109\\nvalue = [74, 24, 11]'),\n",
       " Text(205.86546854942233, 10.872000000000014, 'entropy = 0.642\\nsamples = 50\\nvalue = [17, 11, 22]'),\n",
       " Text(207.1548138639281, 32.615999999999985, 'X[61] <= 2.188\\nentropy = 0.651\\nsamples = 1706\\nvalue = [462, 739, 505]'),\n",
       " Text(206.72503209242618, 10.872000000000014, 'entropy = 0.656\\nsamples = 1256\\nvalue = [325, 504, 427]'),\n",
       " Text(207.58459563543002, 10.872000000000014, 'entropy = 0.605\\nsamples = 450\\nvalue = [137, 235, 78]'),\n",
       " Text(214.89088575096278, 97.848, 'X[158] <= 4.5\\nentropy = 0.615\\nsamples = 6364\\nvalue = [1047, 2230, 3087]'),\n",
       " Text(211.45263157894738, 76.10399999999998, 'X[35] <= 5.039\\nentropy = 0.63\\nsamples = 4591\\nvalue = [854, 1659, 2078]'),\n",
       " Text(209.73350449293966, 54.360000000000014, 'X[312] <= 3565.5\\nentropy = 0.644\\nsamples = 2276\\nvalue = [480, 914, 882]'),\n",
       " Text(208.87394094993581, 32.615999999999985, 'X[38] <= 2.5\\nentropy = 0.655\\nsamples = 1231\\nvalue = [314, 413, 504]'),\n",
       " Text(208.4441591784339, 10.872000000000014, 'entropy = 0.665\\nsamples = 743\\nvalue = [227, 248, 268]'),\n",
       " Text(209.30372272143774, 10.872000000000014, 'entropy = 0.62\\nsamples = 488\\nvalue = [87, 165, 236]'),\n",
       " Text(210.5930680359435, 32.615999999999985, 'X[85] <= 1.5\\nentropy = 0.614\\nsamples = 1045\\nvalue = [166, 501, 378]'),\n",
       " Text(210.16328626444158, 10.872000000000014, 'entropy = 0.495\\nsamples = 109\\nvalue = [15, 73, 21]'),\n",
       " Text(211.02284980744543, 10.872000000000014, 'entropy = 0.619\\nsamples = 936\\nvalue = [151, 428, 357]'),\n",
       " Text(213.17175866495506, 54.360000000000014, 'X[256] <= 4.188\\nentropy = 0.603\\nsamples = 2315\\nvalue = [374, 745, 1196]'),\n",
       " Text(212.31219512195122, 32.615999999999985, 'X[32] <= 8.5\\nentropy = 0.63\\nsamples = 796\\nvalue = [144, 302, 350]'),\n",
       " Text(211.8824133504493, 10.872000000000014, 'entropy = 0.64\\nsamples = 631\\nvalue = [127, 254, 250]'),\n",
       " Text(212.74197689345314, 10.872000000000014, 'entropy = 0.537\\nsamples = 165\\nvalue = [17, 48, 100]'),\n",
       " Text(214.0313222079589, 32.615999999999985, 'X[121] <= 3.5\\nentropy = 0.582\\nsamples = 1519\\nvalue = [230, 443, 846]'),\n",
       " Text(213.601540436457, 10.872000000000014, 'entropy = 0.598\\nsamples = 1304\\nvalue = [208, 407, 689]'),\n",
       " Text(214.46110397946083, 10.872000000000014, 'entropy = 0.428\\nsamples = 215\\nvalue = [22, 36, 157]'),\n",
       " Text(218.3291399229782, 76.10399999999998, 'X[164] <= 3.5\\nentropy = 0.561\\nsamples = 1773\\nvalue = [193, 571, 1009]'),\n",
       " Text(216.61001283697047, 54.360000000000014, 'X[294] <= 2.5\\nentropy = 0.6\\nsamples = 665\\nvalue = [87, 256, 322]'),\n",
       " Text(215.75044929396662, 32.615999999999985, 'X[99] <= 1.5\\nentropy = 0.58\\nsamples = 419\\nvalue = [51, 143, 225]'),\n",
       " Text(215.3206675224647, 10.872000000000014, 'entropy = 0.614\\nsamples = 80\\nvalue = [14, 40, 26]'),\n",
       " Text(216.18023106546855, 10.872000000000014, 'entropy = 0.551\\nsamples = 339\\nvalue = [37, 103, 199]'),\n",
       " Text(217.4695763799743, 32.615999999999985, 'X[108] <= 2.5\\nentropy = 0.612\\nsamples = 246\\nvalue = [36, 113, 97]'),\n",
       " Text(217.0397946084724, 10.872000000000014, 'entropy = 0.63\\nsamples = 119\\nvalue = [28, 58, 33]'),\n",
       " Text(217.89935815147624, 10.872000000000014, 'entropy = 0.555\\nsamples = 127\\nvalue = [8, 55, 64]'),\n",
       " Text(220.04826700898587, 54.360000000000014, 'X[44] <= 3.5\\nentropy = 0.526\\nsamples = 1108\\nvalue = [106, 315, 687]'),\n",
       " Text(219.18870346598203, 32.615999999999985, 'X[298] <= 4.5\\nentropy = 0.552\\nsamples = 790\\nvalue = [82, 249, 459]'),\n",
       " Text(218.7589216944801, 10.872000000000014, 'entropy = 0.567\\nsamples = 663\\nvalue = [71, 225, 367]'),\n",
       " Text(219.61848523748395, 10.872000000000014, 'entropy = 0.432\\nsamples = 127\\nvalue = [11, 24, 92]'),\n",
       " Text(220.90783055198972, 32.615999999999985, 'X[113] <= 3.937\\nentropy = 0.437\\nsamples = 318\\nvalue = [24, 66, 228]'),\n",
       " Text(220.4780487804878, 10.872000000000014, 'entropy = 0.326\\nsamples = 157\\nvalue = [11, 19, 127]'),\n",
       " Text(221.33761232349164, 10.872000000000014, 'entropy = 0.515\\nsamples = 161\\nvalue = [13, 47, 101]'),\n",
       " Text(246.80218228498074, 141.336, 'X[61] <= 5.602\\nentropy = 0.58\\nsamples = 10467\\nvalue = [2189, 2280, 5998]'),\n",
       " Text(235.35924261874197, 119.592, 'X[45] <= 2.5\\nentropy = 0.568\\nsamples = 10026\\nvalue = [1917, 2205, 5904]'),\n",
       " Text(228.64390243902437, 97.848, 'X[40] <= 1.5\\nentropy = 0.623\\nsamples = 3722\\nvalue = [933, 912, 1877]'),\n",
       " Text(225.20564826700897, 76.10399999999998, 'X[115] <= 3.302\\nentropy = 0.651\\nsamples = 1392\\nvalue = [483, 333, 576]'),\n",
       " Text(223.48652118100128, 54.360000000000014, 'X[123] <= 3.5\\nentropy = 0.646\\nsamples = 794\\nvalue = [333, 176, 285]'),\n",
       " Text(222.62695763799744, 32.615999999999985, 'X[43] <= 4.881\\nentropy = 0.641\\nsamples = 475\\nvalue = [169, 100, 206]'),\n",
       " Text(222.1971758664955, 10.872000000000014, 'entropy = 0.58\\nsamples = 145\\nvalue = [34, 28, 83]'),\n",
       " Text(223.05673940949936, 10.872000000000014, 'entropy = 0.646\\nsamples = 330\\nvalue = [135, 72, 123]'),\n",
       " Text(224.34608472400512, 32.615999999999985, 'X[52] <= 2.993\\nentropy = 0.618\\nsamples = 319\\nvalue = [164, 76, 79]'),\n",
       " Text(223.9163029525032, 10.872000000000014, 'entropy = 0.653\\nsamples = 92\\nvalue = [29, 24, 39]'),\n",
       " Text(224.77586649550705, 10.872000000000014, 'entropy = 0.563\\nsamples = 227\\nvalue = [135, 52, 40]'),\n",
       " Text(226.92477535301668, 54.360000000000014, 'X[33] <= 7.5\\nentropy = 0.631\\nsamples = 598\\nvalue = [150, 157, 291]'),\n",
       " Text(226.06521181001284, 32.615999999999985, 'X[198] <= 3.25\\nentropy = 0.649\\nsamples = 502\\nvalue = [140, 140, 222]'),\n",
       " Text(225.63543003851092, 10.872000000000014, 'entropy = 0.573\\nsamples = 160\\nvalue = [49, 21, 90]'),\n",
       " Text(226.49499358151476, 10.872000000000014, 'entropy = 0.659\\nsamples = 342\\nvalue = [91, 119, 132]'),\n",
       " Text(227.78433889602053, 32.615999999999985, 'X[138] <= 2.5\\nentropy = 0.441\\nsamples = 96\\nvalue = [10, 17, 69]'),\n",
       " Text(227.3545571245186, 10.872000000000014, 'entropy = 0.635\\nsamples = 28\\nvalue = [6, 9, 13]'),\n",
       " Text(228.21412066752245, 10.872000000000014, 'entropy = 0.304\\nsamples = 68\\nvalue = [4, 8, 56]'),\n",
       " Text(232.08215661103978, 76.10399999999998, 'X[37] <= 5.171\\nentropy = 0.589\\nsamples = 2330\\nvalue = [450, 579, 1301]'),\n",
       " Text(230.3630295250321, 54.360000000000014, 'X[162] <= 5.906\\nentropy = 0.627\\nsamples = 1208\\nvalue = [268, 347, 593]'),\n",
       " Text(229.50346598202825, 32.615999999999985, 'X[179] <= 1961.5\\nentropy = 0.642\\nsamples = 1058\\nvalue = [252, 324, 482]'),\n",
       " Text(229.07368421052632, 10.872000000000014, 'entropy = 0.665\\nsamples = 414\\nvalue = [139, 124, 151]'),\n",
       " Text(229.93324775353017, 10.872000000000014, 'entropy = 0.609\\nsamples = 644\\nvalue = [113, 200, 331]'),\n",
       " Text(231.22259306803593, 32.615999999999985, 'X[125] <= 3.5\\nentropy = 0.418\\nsamples = 150\\nvalue = [16, 23, 111]'),\n",
       " Text(230.792811296534, 10.872000000000014, 'entropy = 0.624\\nsamples = 40\\nvalue = [9, 11, 20]'),\n",
       " Text(231.65237483953786, 10.872000000000014, 'entropy = 0.3\\nsamples = 110\\nvalue = [7, 12, 91]'),\n",
       " Text(233.8012836970475, 54.360000000000014, 'X[120] <= 4.5\\nentropy = 0.533\\nsamples = 1122\\nvalue = [182, 232, 708]'),\n",
       " Text(232.94172015404365, 32.615999999999985, 'X[32] <= 5.5\\nentropy = 0.564\\nsamples = 846\\nvalue = [154, 190, 502]'),\n",
       " Text(232.51193838254173, 10.872000000000014, 'entropy = 0.646\\nsamples = 96\\nvalue = [21, 36, 39]'),\n",
       " Text(233.37150192554557, 10.872000000000014, 'entropy = 0.545\\nsamples = 750\\nvalue = [133, 154, 463]'),\n",
       " Text(234.66084724005134, 32.615999999999985, 'X[0] <= 0.805\\nentropy = 0.409\\nsamples = 276\\nvalue = [28, 42, 206]'),\n",
       " Text(234.23106546854942, 10.872000000000014, 'entropy = 0.588\\nsamples = 43\\nvalue = [6, 14, 23]'),\n",
       " Text(235.09062901155326, 10.872000000000014, 'entropy = 0.36\\nsamples = 233\\nvalue = [22, 28, 183]'),\n",
       " Text(242.07458279845955, 97.848, 'X[34] <= 6.5\\nentropy = 0.525\\nsamples = 6304\\nvalue = [984, 1293, 4027]'),\n",
       " Text(238.9586649550706, 76.10399999999998, 'X[197] <= 3.167\\nentropy = 0.556\\nsamples = 5188\\nvalue = [909, 1145, 3134]'),\n",
       " Text(237.2395378690629, 54.360000000000014, 'X[59] <= 2.97\\nentropy = 0.488\\nsamples = 2128\\nvalue = [335, 349, 1444]'),\n",
       " Text(236.37997432605906, 32.615999999999985, 'X[64] <= 5.051\\nentropy = 0.37\\nsamples = 751\\nvalue = [67, 100, 584]'),\n",
       " Text(235.9501925545571, 10.872000000000014, 'entropy = 0.532\\nsamples = 319\\nvalue = [47, 71, 201]'),\n",
       " Text(236.80975609756098, 10.872000000000014, 'entropy = 0.207\\nsamples = 432\\nvalue = [20, 29, 383]'),\n",
       " Text(238.09910141206674, 32.615999999999985, 'X[31] <= 3.5\\nentropy = 0.539\\nsamples = 1377\\nvalue = [268, 249, 860]'),\n",
       " Text(237.66931964056482, 10.872000000000014, 'entropy = 0.594\\nsamples = 386\\nvalue = [120, 60, 206]'),\n",
       " Text(238.52888318356867, 10.872000000000014, 'entropy = 0.506\\nsamples = 991\\nvalue = [148, 189, 654]'),\n",
       " Text(240.6777920410783, 54.360000000000014, 'X[30] <= 1.5\\nentropy = 0.592\\nsamples = 3060\\nvalue = [574, 796, 1690]'),\n",
       " Text(239.81822849807446, 32.615999999999985, 'X[34] <= 4.795\\nentropy = 0.597\\nsamples = 876\\nvalue = [245, 157, 474]'),\n",
       " Text(239.3884467265725, 10.872000000000014, 'entropy = 0.619\\nsamples = 509\\nvalue = [189, 83, 237]'),\n",
       " Text(240.24801026957638, 10.872000000000014, 'entropy = 0.519\\nsamples = 367\\nvalue = [56, 74, 237]'),\n",
       " Text(241.53735558408215, 32.615999999999985, 'X[244] <= 55.5\\nentropy = 0.582\\nsamples = 2184\\nvalue = [329, 639, 1216]'),\n",
       " Text(241.10757381258023, 10.872000000000014, 'entropy = 0.605\\nsamples = 1659\\nvalue = [275, 530, 854]'),\n",
       " Text(241.96713735558407, 10.872000000000014, 'entropy = 0.471\\nsamples = 525\\nvalue = [54, 109, 362]'),\n",
       " Text(245.19050064184853, 76.10399999999998, 'X[196] <= 3.594\\nentropy = 0.338\\nsamples = 1116\\nvalue = [75, 148, 893]'),\n",
       " Text(244.1160462130937, 54.360000000000014, 'X[30] <= 1.5\\nentropy = 0.291\\nsamples = 946\\nvalue = [43, 116, 787]'),\n",
       " Text(243.25648267008987, 32.615999999999985, 'X[139] <= 1.5\\nentropy = 0.2\\nsamples = 569\\nvalue = [23, 39, 507]'),\n",
       " Text(242.82670089858792, 10.872000000000014, 'entropy = 0.42\\nsamples = 63\\nvalue = [4, 13, 46]'),\n",
       " Text(243.6862644415918, 10.872000000000014, 'entropy = 0.166\\nsamples = 506\\nvalue = [19, 26, 461]'),\n",
       " Text(244.97560975609755, 32.615999999999985, 'X[92] <= 5.5\\nentropy = 0.404\\nsamples = 377\\nvalue = [20, 77, 280]'),\n",
       " Text(244.54582798459563, 10.872000000000014, 'entropy = 0.436\\nsamples = 315\\nvalue = [17, 74, 224]'),\n",
       " Text(245.40539152759948, 10.872000000000014, 'entropy = 0.18\\nsamples = 62\\nvalue = [3, 3, 56]'),\n",
       " Text(246.26495507060332, 54.360000000000014, 'X[44] <= 1.5\\nentropy = 0.54\\nsamples = 170\\nvalue = [32, 32, 106]'),\n",
       " Text(245.8351732991014, 32.615999999999985, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(246.69473684210527, 32.615999999999985, 'X[136] <= 3.5\\nentropy = 0.527\\nsamples = 166\\nvalue = [28, 32, 106]'),\n",
       " Text(246.26495507060332, 10.872000000000014, 'entropy = 0.443\\nsamples = 108\\nvalue = [9, 22, 77]'),\n",
       " Text(247.1245186136072, 10.872000000000014, 'entropy = 0.613\\nsamples = 58\\nvalue = [19, 10, 29]'),\n",
       " Text(258.2451219512195, 119.592, 'X[257] <= 3.5\\nentropy = 0.545\\nsamples = 441\\nvalue = [272, 75, 94]'),\n",
       " Text(252.1744544287548, 97.848, 'X[63] <= 1.305\\nentropy = 0.464\\nsamples = 351\\nvalue = [245, 40, 66]'),\n",
       " Text(249.05853658536586, 76.10399999999998, 'X[16] <= 2.5\\nentropy = 0.476\\nsamples = 29\\nvalue = [5, 4, 20]'),\n",
       " Text(247.98408215661104, 54.360000000000014, 'X[176] <= 5.5\\nentropy = 0.375\\nsamples = 4\\nvalue = [1, 3, 0]'),\n",
       " Text(247.55430038510912, 32.615999999999985, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(248.41386392811296, 32.615999999999985, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(250.13299101412065, 54.360000000000014, 'X[246] <= 36.0\\nentropy = 0.333\\nsamples = 25\\nvalue = [4, 1, 20]'),\n",
       " Text(249.2734274711168, 32.615999999999985, 'X[94] <= 2.5\\nentropy = 0.375\\nsamples = 4\\nvalue = [3, 0, 1]'),\n",
       " Text(248.84364569961488, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(249.70320924261873, 10.872000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(250.99255455712452, 32.615999999999985, 'X[158] <= 2.5\\nentropy = 0.177\\nsamples = 21\\nvalue = [1, 1, 19]'),\n",
       " Text(250.5627727856226, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(251.42233632862644, 10.872000000000014, 'entropy = 0.095\\nsamples = 20\\nvalue = [1, 0, 19]'),\n",
       " Text(255.29037227214377, 76.10399999999998, 'X[292] <= 1.5\\nentropy = 0.412\\nsamples = 322\\nvalue = [240, 36, 46]'),\n",
       " Text(253.57124518613605, 54.360000000000014, 'X[58] <= 0.5\\nentropy = 0.22\\nsamples = 165\\nvalue = [145, 11, 9]'),\n",
       " Text(252.7116816431322, 32.615999999999985, 'X[100] <= 2.5\\nentropy = 0.625\\nsamples = 8\\nvalue = [2, 2, 4]'),\n",
       " Text(252.2818998716303, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(253.14146341463413, 10.872000000000014, 'entropy = 0.5\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(254.43080872913993, 32.615999999999985, 'X[32] <= 4.5\\nentropy = 0.166\\nsamples = 157\\nvalue = [143, 9, 5]'),\n",
       " Text(254.001026957638, 10.872000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(254.86059050064185, 10.872000000000014, 'entropy = 0.135\\nsamples = 154\\nvalue = [143, 6, 5]'),\n",
       " Text(257.00949935815146, 54.360000000000014, 'X[98] <= 2.098\\nentropy = 0.553\\nsamples = 157\\nvalue = [95, 25, 37]'),\n",
       " Text(256.1499358151476, 32.615999999999985, 'X[73] <= 0.5\\nentropy = 0.474\\nsamples = 109\\nvalue = [75, 22, 12]'),\n",
       " Text(255.7201540436457, 10.872000000000014, 'entropy = 0.425\\nsamples = 98\\nvalue = [72, 14, 12]'),\n",
       " Text(256.57971758664956, 10.872000000000014, 'entropy = 0.397\\nsamples = 11\\nvalue = [3, 8, 0]'),\n",
       " Text(257.8690629011553, 32.615999999999985, 'X[321] <= 16.5\\nentropy = 0.551\\nsamples = 48\\nvalue = [20, 3, 25]'),\n",
       " Text(257.4392811296534, 10.872000000000014, 'entropy = 0.438\\nsamples = 30\\nvalue = [8, 1, 21]'),\n",
       " Text(258.29884467265725, 10.872000000000014, 'entropy = 0.494\\nsamples = 18\\nvalue = [12, 2, 4]'),\n",
       " Text(264.3157894736842, 97.848, 'X[89] <= 4.5\\nentropy = 0.662\\nsamples = 90\\nvalue = [27, 35, 28]'),\n",
       " Text(262.1668806161746, 76.10399999999998, 'X[21] <= 1.5\\nentropy = 0.634\\nsamples = 75\\nvalue = [24, 35, 16]'),\n",
       " Text(260.4477535301669, 54.360000000000014, 'X[181] <= 2009.5\\nentropy = 0.634\\nsamples = 47\\nvalue = [22, 15, 10]'),\n",
       " Text(259.58818998716305, 32.615999999999985, 'X[109] <= 2.5\\nentropy = 0.502\\nsamples = 29\\nvalue = [19, 7, 3]'),\n",
       " Text(259.1584082156611, 10.872000000000014, 'entropy = 0.39\\nsamples = 25\\nvalue = [19, 4, 2]'),\n",
       " Text(260.01797175866494, 10.872000000000014, 'entropy = 0.375\\nsamples = 4\\nvalue = [0, 3, 1]'),\n",
       " Text(261.30731707317074, 32.615999999999985, 'X[57] <= 2.5\\nentropy = 0.623\\nsamples = 18\\nvalue = [3, 8, 7]'),\n",
       " Text(260.8775353016688, 10.872000000000014, 'entropy = 0.604\\nsamples = 13\\nvalue = [3, 3, 7]'),\n",
       " Text(261.73709884467263, 10.872000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
       " Text(263.88600770218227, 54.360000000000014, 'X[111] <= 1.5\\nentropy = 0.439\\nsamples = 28\\nvalue = [2, 20, 6]'),\n",
       " Text(263.0264441591784, 32.615999999999985, 'X[305] <= 2.5\\nentropy = 0.408\\nsamples = 7\\nvalue = [0, 2, 5]'),\n",
       " Text(262.5966623876765, 10.872000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 0, 5]'),\n",
       " Text(263.4562259306804, 10.872000000000014, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(264.7455712451861, 32.615999999999985, 'X[300] <= 3.5\\nentropy = 0.254\\nsamples = 21\\nvalue = [2, 18, 1]'),\n",
       " Text(264.3157894736842, 10.872000000000014, 'entropy = 0.1\\nsamples = 19\\nvalue = [1, 18, 0]'),\n",
       " Text(265.17535301668806, 10.872000000000014, 'entropy = 0.5\\nsamples = 2\\nvalue = [1, 0, 1]'),\n",
       " Text(266.46469833119386, 76.10399999999998, 'X[19] <= 2.5\\nentropy = 0.32\\nsamples = 15\\nvalue = [3, 0, 12]'),\n",
       " Text(266.0349165596919, 54.360000000000014, 'X[253] <= 4.0\\nentropy = 0.375\\nsamples = 4\\nvalue = [3, 0, 1]'),\n",
       " Text(265.60513478818996, 32.615999999999985, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(266.46469833119386, 32.615999999999985, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(266.89448010269575, 54.360000000000014, 'entropy = 0.0\\nsamples = 11\\nvalue = [0, 0, 11]'),\n",
       " Text(306.8910462130937, 163.07999999999998, 'X[195] <= 3.969\\nentropy = 0.659\\nsamples = 4383\\nvalue = [1698, 1531, 1154]'),\n",
       " Text(289.9415275994865, 141.336, 'X[30] <= 1.5\\nentropy = 0.65\\nsamples = 3952\\nvalue = [1605, 1427, 920]'),\n",
       " Text(278.6060333761232, 119.592, 'X[48] <= 6.076\\nentropy = 0.655\\nsamples = 2004\\nvalue = [844, 589, 571]'),\n",
       " Text(272.5890885750963, 97.848, 'X[88] <= 3.5\\nentropy = 0.666\\nsamples = 1180\\nvalue = [406, 372, 402]'),\n",
       " Text(269.25827984595634, 76.10399999999998, 'X[64] <= 4.402\\nentropy = 0.655\\nsamples = 599\\nvalue = [252, 168, 179]'),\n",
       " Text(267.7540436456996, 54.360000000000014, 'X[182] <= 1985.5\\nentropy = 0.576\\nsamples = 180\\nvalue = [102, 51, 27]'),\n",
       " Text(267.3242618741977, 32.615999999999985, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(268.18382541720155, 32.615999999999985, 'X[35] <= 7.5\\nentropy = 0.563\\nsamples = 176\\nvalue = [102, 51, 23]'),\n",
       " Text(267.7540436456996, 10.872000000000014, 'entropy = 0.516\\nsamples = 142\\nvalue = [91, 35, 16]'),\n",
       " Text(268.61360718870344, 10.872000000000014, 'entropy = 0.631\\nsamples = 34\\nvalue = [11, 16, 7]'),\n",
       " Text(270.7625160462131, 54.360000000000014, 'X[126] <= 4.5\\nentropy = 0.662\\nsamples = 419\\nvalue = [150, 117, 152]'),\n",
       " Text(269.90295250320924, 32.615999999999985, 'X[1] <= 0.233\\nentropy = 0.646\\nsamples = 243\\nvalue = [109, 62, 72]'),\n",
       " Text(269.4731707317073, 10.872000000000014, 'entropy = 0.314\\nsamples = 11\\nvalue = [1, 1, 9]'),\n",
       " Text(270.3327342747112, 10.872000000000014, 'entropy = 0.64\\nsamples = 232\\nvalue = [108, 61, 63]'),\n",
       " Text(271.6220795892169, 32.615999999999985, 'X[191] <= 1.581\\nentropy = 0.641\\nsamples = 176\\nvalue = [41, 55, 80]'),\n",
       " Text(271.19229781771503, 10.872000000000014, 'entropy = 0.65\\nsamples = 128\\nvalue = [29, 49, 50]'),\n",
       " Text(272.0518613607189, 10.872000000000014, 'entropy = 0.531\\nsamples = 48\\nvalue = [12, 6, 30]'),\n",
       " Text(275.9198973042362, 76.10399999999998, 'X[166] <= 1.5\\nentropy = 0.659\\nsamples = 581\\nvalue = [154, 204, 223]'),\n",
       " Text(274.2007702182285, 54.360000000000014, 'X[92] <= 4.5\\nentropy = 0.632\\nsamples = 309\\nvalue = [65, 98, 146]'),\n",
       " Text(273.34120667522467, 32.615999999999985, 'X[256] <= 3.5\\nentropy = 0.527\\nsamples = 146\\nvalue = [23, 30, 93]'),\n",
       " Text(272.9114249037227, 10.872000000000014, 'entropy = 0.663\\nsamples = 24\\nvalue = [7, 9, 8]'),\n",
       " Text(273.77098844672656, 10.872000000000014, 'entropy = 0.468\\nsamples = 122\\nvalue = [16, 21, 85]'),\n",
       " Text(275.06033376123236, 32.615999999999985, 'X[123] <= 2.5\\nentropy = 0.654\\nsamples = 163\\nvalue = [42, 68, 53]'),\n",
       " Text(274.6305519897304, 10.872000000000014, 'entropy = 0.584\\nsamples = 83\\nvalue = [9, 42, 32]'),\n",
       " Text(275.49011553273425, 10.872000000000014, 'entropy = 0.655\\nsamples = 80\\nvalue = [33, 26, 21]'),\n",
       " Text(277.6390243902439, 54.360000000000014, 'X[137] <= 3.5\\nentropy = 0.661\\nsamples = 272\\nvalue = [89, 106, 77]'),\n",
       " Text(276.77946084724005, 32.615999999999985, 'X[93] <= 1.5\\nentropy = 0.635\\nsamples = 151\\nvalue = [37, 72, 42]'),\n",
       " Text(276.3496790757381, 10.872000000000014, 'entropy = 0.462\\nsamples = 13\\nvalue = [9, 1, 3]'),\n",
       " Text(277.209242618742, 10.872000000000014, 'entropy = 0.614\\nsamples = 138\\nvalue = [28, 71, 39]'),\n",
       " Text(278.49858793324773, 32.615999999999985, 'X[14] <= 3.972\\nentropy = 0.653\\nsamples = 121\\nvalue = [52, 34, 35]'),\n",
       " Text(278.06880616174584, 10.872000000000014, 'entropy = 0.654\\nsamples = 50\\nvalue = [12, 19, 19]'),\n",
       " Text(278.9283697047497, 10.872000000000014, 'entropy = 0.587\\nsamples = 71\\nvalue = [40, 15, 16]'),\n",
       " Text(284.6229781771502, 97.848, 'X[66] <= 6.5\\nentropy = 0.606\\nsamples = 824\\nvalue = [438, 217, 169]'),\n",
       " Text(281.29216944801027, 76.10399999999998, 'X[27] <= 1.5\\nentropy = 0.644\\nsamples = 518\\nvalue = [233, 159, 126]'),\n",
       " Text(279.78793324775353, 54.360000000000014, 'X[112] <= 2.5\\nentropy = 0.395\\nsamples = 60\\nvalue = [45, 12, 3]'),\n",
       " Text(279.3581514762516, 32.615999999999985, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(280.2177150192554, 32.615999999999985, 'X[310] <= 2.5\\nentropy = 0.349\\nsamples = 57\\nvalue = [45, 9, 3]'),\n",
       " Text(279.78793324775353, 10.872000000000014, 'entropy = 0.583\\nsamples = 22\\nvalue = [12, 7, 3]'),\n",
       " Text(280.6474967907574, 10.872000000000014, 'entropy = 0.108\\nsamples = 35\\nvalue = [33, 2, 0]'),\n",
       " Text(282.796405648267, 54.360000000000014, 'X[65] <= 4.5\\nentropy = 0.656\\nsamples = 458\\nvalue = [188, 147, 123]'),\n",
       " Text(281.93684210526317, 32.615999999999985, 'X[50] <= 7.378\\nentropy = 0.663\\nsamples = 195\\nvalue = [64, 57, 74]'),\n",
       " Text(281.5070603337612, 10.872000000000014, 'entropy = 0.596\\nsamples = 59\\nvalue = [30, 8, 21]'),\n",
       " Text(282.36662387676506, 10.872000000000014, 'entropy = 0.656\\nsamples = 136\\nvalue = [34, 49, 53]'),\n",
       " Text(283.65596919127086, 32.615999999999985, 'X[140] <= 2.5\\nentropy = 0.626\\nsamples = 263\\nvalue = [124, 90, 49]'),\n",
       " Text(283.2261874197689, 10.872000000000014, 'entropy = 0.649\\nsamples = 138\\nvalue = [52, 55, 31]'),\n",
       " Text(284.0857509627728, 10.872000000000014, 'entropy = 0.569\\nsamples = 125\\nvalue = [72, 35, 18]'),\n",
       " Text(287.95378690629013, 76.10399999999998, 'X[123] <= 3.5\\nentropy = 0.496\\nsamples = 306\\nvalue = [205, 58, 43]'),\n",
       " Text(286.2346598202824, 54.360000000000014, 'X[237] <= 1.5\\nentropy = 0.58\\nsamples = 184\\nvalue = [105, 46, 33]'),\n",
       " Text(285.37509627727854, 32.615999999999985, 'X[26] <= 1.5\\nentropy = 0.631\\nsamples = 15\\nvalue = [3, 5, 7]'),\n",
       " Text(284.94531450577665, 10.872000000000014, 'entropy = 0.568\\nsamples = 9\\nvalue = [3, 5, 1]'),\n",
       " Text(285.8048780487805, 10.872000000000014, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(287.09422336328623, 32.615999999999985, 'X[9] <= 1.5\\nentropy = 0.553\\nsamples = 169\\nvalue = [102, 41, 26]'),\n",
       " Text(286.66444159178434, 10.872000000000014, 'entropy = 0.261\\nsamples = 34\\nvalue = [29, 2, 3]'),\n",
       " Text(287.5240051347882, 10.872000000000014, 'entropy = 0.595\\nsamples = 135\\nvalue = [73, 39, 23]'),\n",
       " Text(289.6729139922978, 54.360000000000014, 'X[117] <= 5.5\\nentropy = 0.312\\nsamples = 122\\nvalue = [100, 12, 10]'),\n",
       " Text(288.813350449294, 32.615999999999985, 'X[85] <= 1.5\\nentropy = 0.176\\nsamples = 95\\nvalue = [86, 4, 5]'),\n",
       " Text(288.383568677792, 10.872000000000014, 'entropy = 0.625\\nsamples = 4\\nvalue = [1, 2, 1]'),\n",
       " Text(289.24313222079587, 10.872000000000014, 'entropy = 0.125\\nsamples = 91\\nvalue = [85, 2, 4]'),\n",
       " Text(290.53247753530167, 32.615999999999985, 'X[106] <= 3.5\\nentropy = 0.609\\nsamples = 27\\nvalue = [14, 8, 5]'),\n",
       " Text(290.1026957637997, 10.872000000000014, 'entropy = 0.529\\nsamples = 22\\nvalue = [14, 4, 4]'),\n",
       " Text(290.96225930680356, 10.872000000000014, 'entropy = 0.32\\nsamples = 5\\nvalue = [0, 4, 1]'),\n",
       " Text(301.2770218228498, 119.592, 'X[131] <= 7.5\\nentropy = 0.63\\nsamples = 1948\\nvalue = [761, 838, 349]'),\n",
       " Text(297.51643132220795, 97.848, 'X[60] <= 1.5\\nentropy = 0.63\\nsamples = 1873\\nvalue = [703, 830, 340]'),\n",
       " Text(294.83029525032094, 76.10399999999998, 'X[33] <= 0.5\\nentropy = 0.635\\nsamples = 1053\\nvalue = [346, 486, 221]'),\n",
       " Text(293.1111681643132, 54.360000000000014, 'X[140] <= 1.5\\nentropy = 0.585\\nsamples = 77\\nvalue = [42, 24, 11]'),\n",
       " Text(292.25160462130935, 32.615999999999985, 'X[291] <= 5.5\\nentropy = 0.449\\nsamples = 14\\nvalue = [2, 10, 2]'),\n",
       " Text(291.82182284980746, 10.872000000000014, 'entropy = 0.0\\nsamples = 10\\nvalue = [0, 10, 0]'),\n",
       " Text(292.6813863928113, 10.872000000000014, 'entropy = 0.5\\nsamples = 4\\nvalue = [2, 0, 2]'),\n",
       " Text(293.97073170731704, 32.615999999999985, 'X[247] <= 95.5\\nentropy = 0.527\\nsamples = 63\\nvalue = [40, 14, 9]'),\n",
       " Text(293.54094993581515, 10.872000000000014, 'entropy = 0.446\\nsamples = 56\\nvalue = [40, 10, 6]'),\n",
       " Text(294.400513478819, 10.872000000000014, 'entropy = 0.49\\nsamples = 7\\nvalue = [0, 4, 3]'),\n",
       " Text(296.54942233632863, 54.360000000000014, 'X[312] <= 10009830.0\\nentropy = 0.633\\nsamples = 976\\nvalue = [304, 462, 210]'),\n",
       " Text(295.6898587933248, 32.615999999999985, 'X[20] <= 4.919\\nentropy = 0.624\\nsamples = 900\\nvalue = [275, 442, 183]'),\n",
       " Text(295.26007702182284, 10.872000000000014, 'entropy = 0.645\\nsamples = 420\\nvalue = [151, 177, 92]'),\n",
       " Text(296.1196405648267, 10.872000000000014, 'entropy = 0.593\\nsamples = 480\\nvalue = [124, 265, 91]'),\n",
       " Text(297.4089858793325, 32.615999999999985, 'X[317] <= 18.5\\nentropy = 0.659\\nsamples = 76\\nvalue = [29, 20, 27]'),\n",
       " Text(296.9792041078305, 10.872000000000014, 'entropy = 0.588\\nsamples = 33\\nvalue = [17, 12, 4]'),\n",
       " Text(297.83876765083437, 10.872000000000014, 'entropy = 0.601\\nsamples = 43\\nvalue = [12, 8, 23]'),\n",
       " Text(300.202567394095, 76.10399999999998, 'X[158] <= 1.5\\nentropy = 0.613\\nsamples = 820\\nvalue = [357, 344, 119]'),\n",
       " Text(298.69833119383827, 54.360000000000014, 'X[116] <= 1.5\\nentropy = 0.492\\nsamples = 73\\nvalue = [15, 49, 9]'),\n",
       " Text(298.2685494223363, 32.615999999999985, 'entropy = 0.0\\nsamples = 22\\nvalue = [0, 22, 0]'),\n",
       " Text(299.12811296534016, 32.615999999999985, 'X[247] <= 60.5\\nentropy = 0.602\\nsamples = 51\\nvalue = [15, 27, 9]'),\n",
       " Text(298.69833119383827, 10.872000000000014, 'entropy = 0.637\\nsamples = 29\\nvalue = [13, 10, 6]'),\n",
       " Text(299.5578947368421, 10.872000000000014, 'entropy = 0.376\\nsamples = 22\\nvalue = [2, 17, 3]'),\n",
       " Text(301.70680359435175, 54.360000000000014, 'X[179] <= 1956.5\\nentropy = 0.613\\nsamples = 747\\nvalue = [342, 295, 110]'),\n",
       " Text(300.84724005134785, 32.615999999999985, 'X[180] <= 1947.5\\nentropy = 0.542\\nsamples = 168\\nvalue = [101, 49, 18]'),\n",
       " Text(300.41745827984596, 10.872000000000014, 'entropy = 0.615\\nsamples = 54\\nvalue = [23, 23, 8]'),\n",
       " Text(301.2770218228498, 10.872000000000014, 'entropy = 0.472\\nsamples = 114\\nvalue = [78, 26, 10]'),\n",
       " Text(302.5663671373556, 32.615999999999985, 'X[48] <= 6.576\\nentropy = 0.621\\nsamples = 579\\nvalue = [241, 246, 92]'),\n",
       " Text(302.13658536585365, 10.872000000000014, 'entropy = 0.631\\nsamples = 407\\nvalue = [146, 184, 77]'),\n",
       " Text(302.9961489088575, 10.872000000000014, 'entropy = 0.557\\nsamples = 172\\nvalue = [95, 62, 15]'),\n",
       " Text(305.03761232349166, 97.848, 'X[180] <= 1935.5\\nentropy = 0.376\\nsamples = 75\\nvalue = [58, 8, 9]'),\n",
       " Text(303.85571245186134, 76.10399999999998, 'X[304] <= 5.5\\nentropy = 0.49\\nsamples = 7\\nvalue = [0, 3, 4]'),\n",
       " Text(303.42593068035944, 54.360000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(304.2854942233633, 54.360000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(306.2195121951219, 76.10399999999998, 'X[180] <= 7221.5\\nentropy = 0.262\\nsamples = 68\\nvalue = [58, 5, 5]'),\n",
       " Text(305.14505776636713, 54.360000000000014, 'X[65] <= 2.5\\nentropy = 0.198\\nsamples = 65\\nvalue = [58, 4, 3]'),\n",
       " Text(304.2854942233633, 32.615999999999985, 'X[115] <= 2.5\\nentropy = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(303.85571245186134, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(304.7152759948652, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(306.004621309371, 32.615999999999985, 'X[19] <= 9.5\\nentropy = 0.149\\nsamples = 63\\nvalue = [58, 3, 2]'),\n",
       " Text(305.5748395378691, 10.872000000000014, 'entropy = 0.122\\nsamples = 62\\nvalue = [58, 3, 1]'),\n",
       " Text(306.4344030808729, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(307.29396662387677, 54.360000000000014, 'X[122] <= 2.5\\nentropy = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(306.8641848523748, 32.615999999999985, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(307.72374839537866, 32.615999999999985, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(323.84056482670087, 141.336, 'X[42] <= 4.5\\nentropy = 0.6\\nsamples = 431\\nvalue = [93, 104, 234]'),\n",
       " Text(317.93106546854943, 119.592, 'X[159] <= 3.5\\nentropy = 0.644\\nsamples = 306\\nvalue = [82, 84, 140]'),\n",
       " Text(312.4513478818999, 97.848, 'X[37] <= 7.5\\nentropy = 0.66\\nsamples = 137\\nvalue = [41, 55, 41]'),\n",
       " Text(310.5173299101412, 76.10399999999998, 'X[6] <= 6.5\\nentropy = 0.613\\nsamples = 97\\nvalue = [28, 50, 19]'),\n",
       " Text(309.4428754813864, 54.360000000000014, 'X[257] <= 2.5\\nentropy = 0.527\\nsamples = 73\\nvalue = [18, 46, 9]'),\n",
       " Text(308.5833119383825, 32.615999999999985, 'X[131] <= 4.5\\nentropy = 0.393\\nsamples = 50\\nvalue = [7, 38, 5]'),\n",
       " Text(308.1535301668806, 10.872000000000014, 'entropy = 0.302\\nsamples = 46\\nvalue = [4, 38, 4]'),\n",
       " Text(309.01309370988446, 10.872000000000014, 'entropy = 0.375\\nsamples = 4\\nvalue = [3, 0, 1]'),\n",
       " Text(310.30243902439025, 32.615999999999985, 'X[50] <= 7.5\\nentropy = 0.62\\nsamples = 23\\nvalue = [11, 8, 4]'),\n",
       " Text(309.8726572528883, 10.872000000000014, 'entropy = 0.5\\nsamples = 12\\nvalue = [2, 8, 2]'),\n",
       " Text(310.73222079589215, 10.872000000000014, 'entropy = 0.298\\nsamples = 11\\nvalue = [9, 0, 2]'),\n",
       " Text(311.591784338896, 54.360000000000014, 'X[180] <= 1955.5\\nentropy = 0.625\\nsamples = 24\\nvalue = [10, 4, 10]'),\n",
       " Text(311.1620025673941, 32.615999999999985, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(312.02156611039794, 32.615999999999985, 'X[40] <= 2.5\\nentropy = 0.593\\nsamples = 18\\nvalue = [4, 4, 10]'),\n",
       " Text(311.591784338896, 10.872000000000014, 'entropy = 0.48\\nsamples = 15\\nvalue = [4, 1, 10]'),\n",
       " Text(312.4513478818999, 10.872000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(314.3853658536585, 76.10399999999998, 'X[65] <= 4.5\\nentropy = 0.576\\nsamples = 40\\nvalue = [13, 5, 22]'),\n",
       " Text(313.31091142490374, 54.360000000000014, 'X[194] <= 5.5\\nentropy = 0.133\\nsamples = 14\\nvalue = [1, 0, 13]'),\n",
       " Text(312.8811296534018, 32.615999999999985, 'entropy = 0.0\\nsamples = 13\\nvalue = [0, 0, 13]'),\n",
       " Text(313.74069319640563, 32.615999999999985, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(315.4598202824133, 54.360000000000014, 'X[115] <= 3.248\\nentropy = 0.63\\nsamples = 26\\nvalue = [12, 5, 9]'),\n",
       " Text(314.6002567394095, 32.615999999999985, 'X[113] <= 2.5\\nentropy = 0.165\\nsamples = 11\\nvalue = [10, 0, 1]'),\n",
       " Text(314.1704749679076, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(315.0300385109114, 10.872000000000014, 'entropy = 0.0\\nsamples = 10\\nvalue = [10, 0, 0]'),\n",
       " Text(316.3193838254172, 32.615999999999985, 'X[292] <= 1.5\\nentropy = 0.587\\nsamples = 15\\nvalue = [2, 5, 8]'),\n",
       " Text(315.88960205391527, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(316.7491655969191, 10.872000000000014, 'entropy = 0.43\\nsamples = 11\\nvalue = [2, 1, 8]'),\n",
       " Text(323.410783055199, 97.848, 'X[61] <= 5.602\\nentropy = 0.569\\nsamples = 169\\nvalue = [41, 29, 99]'),\n",
       " Text(320.61720154043644, 76.10399999999998, 'X[2] <= 0.615\\nentropy = 0.505\\nsamples = 133\\nvalue = [23, 22, 88]'),\n",
       " Text(318.89807445442875, 54.360000000000014, 'X[180] <= 1941.5\\nentropy = 0.415\\nsamples = 109\\nvalue = [15, 13, 81]'),\n",
       " Text(318.0385109114249, 32.615999999999985, 'X[1] <= 2.153\\nentropy = 0.49\\nsamples = 7\\nvalue = [4, 3, 0]'),\n",
       " Text(317.60872913992296, 10.872000000000014, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(318.4682926829268, 10.872000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(319.7576379974326, 32.615999999999985, 'X[318] <= 5.5\\nentropy = 0.348\\nsamples = 102\\nvalue = [11, 10, 81]'),\n",
       " Text(319.32785622593065, 10.872000000000014, 'entropy = 0.562\\nsamples = 22\\nvalue = [8, 2, 12]'),\n",
       " Text(320.18741976893455, 10.872000000000014, 'entropy = 0.245\\nsamples = 80\\nvalue = [3, 8, 69]'),\n",
       " Text(322.33632862644413, 54.360000000000014, 'X[249] <= 6188.5\\nentropy = 0.663\\nsamples = 24\\nvalue = [8, 9, 7]'),\n",
       " Text(321.4767650834403, 32.615999999999985, 'X[180] <= 1938.0\\nentropy = 0.245\\nsamples = 7\\nvalue = [6, 0, 1]'),\n",
       " Text(321.0469833119384, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(321.90654685494223, 10.872000000000014, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(323.19589216944803, 32.615999999999985, 'X[48] <= 6.5\\nentropy = 0.581\\nsamples = 17\\nvalue = [2, 9, 6]'),\n",
       " Text(322.7661103979461, 10.872000000000014, 'entropy = 0.346\\nsamples = 9\\nvalue = [2, 7, 0]'),\n",
       " Text(323.6256739409499, 10.872000000000014, 'entropy = 0.375\\nsamples = 8\\nvalue = [0, 2, 6]'),\n",
       " Text(326.20436456996146, 76.10399999999998, 'X[112] <= 4.292\\nentropy = 0.619\\nsamples = 36\\nvalue = [18, 7, 11]'),\n",
       " Text(325.77458279845956, 54.360000000000014, 'X[21] <= 2.5\\nentropy = 0.537\\nsamples = 29\\nvalue = [18, 7, 4]'),\n",
       " Text(324.9150192554557, 32.615999999999985, 'X[111] <= 1.5\\nentropy = 0.265\\nsamples = 20\\nvalue = [17, 2, 1]'),\n",
       " Text(324.48523748395377, 10.872000000000014, 'entropy = 0.5\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(325.3448010269576, 10.872000000000014, 'entropy = 0.105\\nsamples = 18\\nvalue = [17, 1, 0]'),\n",
       " Text(326.6341463414634, 32.615999999999985, 'X[256] <= 4.736\\nentropy = 0.568\\nsamples = 9\\nvalue = [1, 5, 3]'),\n",
       " Text(326.20436456996146, 10.872000000000014, 'entropy = 0.278\\nsamples = 6\\nvalue = [1, 5, 0]'),\n",
       " Text(327.06392811296536, 10.872000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(326.6341463414634, 54.360000000000014, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 0, 7]'),\n",
       " Text(329.75006418485236, 119.592, 'X[28] <= 1.5\\nentropy = 0.401\\nsamples = 125\\nvalue = [11, 20, 94]'),\n",
       " Text(328.3532734274711, 97.848, 'X[123] <= 3.0\\nentropy = 0.58\\nsamples = 10\\nvalue = [5, 4, 1]'),\n",
       " Text(327.9234916559692, 76.10399999999998, 'X[2] <= 0.239\\nentropy = 0.278\\nsamples = 6\\nvalue = [5, 0, 1]'),\n",
       " Text(327.49370988446725, 54.360000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(328.3532734274711, 54.360000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(328.78305519897305, 76.10399999999998, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(331.14685494223363, 97.848, 'X[286] <= 1.5\\nentropy = 0.324\\nsamples = 115\\nvalue = [6, 16, 93]'),\n",
       " Text(329.6426187419769, 76.10399999999998, 'X[306] <= 4.5\\nentropy = 0.58\\nsamples = 21\\nvalue = [2, 9, 10]'),\n",
       " Text(329.21283697047494, 54.360000000000014, 'X[30] <= 1.5\\nentropy = 0.498\\nsamples = 15\\nvalue = [2, 3, 10]'),\n",
       " Text(328.78305519897305, 32.615999999999985, 'entropy = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(329.6426187419769, 32.615999999999985, 'X[114] <= 2.5\\nentropy = 0.653\\nsamples = 7\\nvalue = [2, 3, 2]'),\n",
       " Text(329.21283697047494, 10.872000000000014, 'entropy = 0.5\\nsamples = 4\\nvalue = [2, 0, 2]'),\n",
       " Text(330.0724005134788, 10.872000000000014, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(330.0724005134788, 54.360000000000014, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(332.6510911424904, 76.10399999999998, 'X[19] <= 5.5\\nentropy = 0.213\\nsamples = 94\\nvalue = [4, 7, 83]'),\n",
       " Text(331.7915275994865, 54.360000000000014, 'X[169] <= 4.5\\nentropy = 0.138\\nsamples = 82\\nvalue = [4, 2, 76]'),\n",
       " Text(331.3617458279846, 32.615999999999985, 'X[64] <= 3.5\\nentropy = 0.118\\nsamples = 81\\nvalue = [3, 2, 76]'),\n",
       " Text(330.9319640564827, 10.872000000000014, 'entropy = 0.512\\nsamples = 11\\nvalue = [3, 1, 7]'),\n",
       " Text(331.7915275994865, 10.872000000000014, 'entropy = 0.028\\nsamples = 70\\nvalue = [0, 1, 69]'),\n",
       " Text(332.2213093709884, 32.615999999999985, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(333.5106546854942, 54.360000000000014, 'X[166] <= 1.5\\nentropy = 0.486\\nsamples = 12\\nvalue = [0, 5, 7]'),\n",
       " Text(333.08087291399227, 32.615999999999985, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 0, 6]'),\n",
       " Text(333.94043645699617, 32.615999999999985, 'X[35] <= 8.0\\nentropy = 0.278\\nsamples = 6\\nvalue = [0, 5, 1]'),\n",
       " Text(333.5106546854942, 10.872000000000014, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
       " Text(334.37021822849806, 10.872000000000014, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(clf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MRpBCAb3GYb"
   },
   "source": [
    "Predict Jowita's political view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "sxwz5iGW3GYb",
    "outputId": "509502d3-480d-438f-9222-56304e3a994c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#create a dataform with all the answers\\n#j_test = data[5, 5,600,8,8,7]\\nj_test = pd.read_csv('/Users/jowi/Desktop/uni/DataMining/DataMining-FinalProject/jowita.csv')\\nj_test_liberal = pd.read_csv('/Users/jowi/Desktop/uni/DataMining/DataMining-FinalProject/jowitaLiberal.csv')\\nj_test_not_Trusting = pd.read_csv('/Users/jowi/Desktop/uni/DataMining/DataMining-FinalProject/jowitaNotTrusting.csv')\\njowita_pred = clf.predict(j_test)\\njowita_pred_liberal = clf.predict(j_test_liberal)\\njowita_pred_not_trusting = clf.predict(j_test_not_Trusting)\\n\\n#predicting for 8 featues\\nj_test = pd.read_csv('/Users/jowi/Desktop/uni/DataMining/DataMining-FinalProject/jowita8features.csv')\\njowita_pred = clf.predict(j_test)\\n\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#create a dataform with all the answers\n",
    "#j_test = data[5, 5,600,8,8,7]\n",
    "j_test = pd.read_csv('/Users/jowi/Desktop/uni/DataMining/DataMining-FinalProject/jowita.csv')\n",
    "j_test_liberal = pd.read_csv('/Users/jowi/Desktop/uni/DataMining/DataMining-FinalProject/jowitaLiberal.csv')\n",
    "j_test_not_Trusting = pd.read_csv('/Users/jowi/Desktop/uni/DataMining/DataMining-FinalProject/jowitaNotTrusting.csv')\n",
    "jowita_pred = clf.predict(j_test)\n",
    "jowita_pred_liberal = clf.predict(j_test_liberal)\n",
    "jowita_pred_not_trusting = clf.predict(j_test_not_Trusting)\n",
    "\n",
    "#predicting for 8 featues\n",
    "j_test = pd.read_csv('/Users/jowi/Desktop/uni/DataMining/DataMining-FinalProject/jowita8features.csv')\n",
    "jowita_pred = clf.predict(j_test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMvSGH8X3GYd"
   },
   "outputs": [],
   "source": [
    "# Predictions 1 - for columns: 'happy','atchctr','pplhlp','trstplt','stflife','imwbcnt','rlgdgr','lkredcc' , to see them uncomment below :\n",
    "#print(data_no_label) \n",
    "#To test it I create I answer those questions (my answer to lrscale3 is 0). I create a csv files with one row for that. Let's see what it will predict for me:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "AmKIm0AJ3GYe",
    "outputId": "7381861a-ded6-40cc-f5f7-0ce4789ef4d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(jowita_pred)\\nprint(jowita_pred_liberal)\\nprint(jowita_pred_not_trusting)\\n\\n#for 8 features: \\nprint(jowita_pred) # correct prediction\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(jowita_pred)\n",
    "print(jowita_pred_liberal)\n",
    "print(jowita_pred_not_trusting)\n",
    "\n",
    "#for 8 features: \n",
    "print(jowita_pred) # correct prediction\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "H5axhvFl3GYg",
    "outputId": "06961e54-4464-44c7-beeb-d5e4b10c0d82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndot_data = tree.export_graphviz(clf, out_file=None, \\n                    filled=True, rounded=True,  \\n                    special_characters=True)  \\ngraph = graphviz.Source(dot_data)  \\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#a better visualisation of a tree.\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf, out_file=None, filled=True, rounded=True, special_characters=False, impurity=False, feature_names = data_no_label.columns) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"our tree\", view=True) \n",
    "\n",
    "\"\"\"\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                    filled=True, rounded=True,  \n",
    "                    special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TX9JHqXD3GYi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMxdVkOC3GYj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7SI4FJf3GYk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "xoWVdNXtmEA4"
   ],
   "name": "project_data_exploration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
